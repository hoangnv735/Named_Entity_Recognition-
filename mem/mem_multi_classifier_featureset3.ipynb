{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mem-multi-classifier-featureset3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gabUUCtVqD36",
        "colab_type": "code",
        "outputId": "74b4d6b4-bd80-49f7-b901-d776a1859efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ceiuGTl2b0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pickle\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.classify.maxent import MaxentClassifier, BinaryMaxentFeatureEncoding\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF24ddXqaxc",
        "colab_type": "code",
        "outputId": "153d5f43-57dc-4fb9-a567-22a1a216472f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Global variables\n",
        "rawdata_path = \"/content/gdrive/My Drive/ml/data/rawdata/\"\n",
        "data_path = \"/content/gdrive/My Drive/ml/data/data/\"\n",
        "model_path = \"/content/gdrive/My Drive/ml/model/\"\n",
        "labels = ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'O']\n",
        "labels_dict = {labels[i]: i for i in range(len(labels))}\n",
        "eval_labels = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
        "print(labels_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOrPZ5D9qn3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "    ''' Create training data and testing data\n",
        "        Format of data: CoNLL\n",
        "\n",
        "        Args:\n",
        "        path: path of data folder\n",
        "        scale: test size\n",
        "        index_attri: Represents the number of attributes and the associated attribute type\n",
        "            index_attri == 1 : The number of attributes = 1 - only ner label. ex: [('Huế', 'B_LOC'), ('là', 'O'), ('thành_phố', 'O'), ('đẹp', 'O')]\n",
        "            index_attri == 2.1 : The number of attributes = 2(pos-tagging label, ner label). ex: [('Đó', 'P', 'O'), ('là', 'V',  'O'), ('con', 'Nc', 'O'), ('đường', 'N', , 'O')]\n",
        "            index_attri = 2.2 : The number of attributes = 2(chunking label, ner label). ex: [('Đó', 'B-NP', 'O'), ('là', 'B-VP', 'O'), ('con', 'B-NP', 'O'), ('đường', 'B-NP', 'O')]\n",
        "            index_attri = 3 : The number of attributes = 3(pos-tagging label,chunking, ner label). ex: [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')]\n",
        "            if index_attri not in {1,2.1,2,2,3} index_attri = 2.1\n",
        "        Return:\n",
        "        train_sents, test_sents\n",
        "        \n",
        "        Example of format data:\n",
        "        [[('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "        [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "    '''    \n",
        "    list_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    ''' Convert data format to CoNll '''\n",
        "    #training data\n",
        "    c = 0;\n",
        "    pos_tag = []\n",
        "    chunk_tag = []\n",
        "    ne_tag = []\n",
        "    for file in list_files:\n",
        "        with codecs.open(path + file,'r',encoding='utf8') as f:\n",
        "            sentence = []\n",
        "            remove = False\n",
        "            for line in f:\n",
        "                line = line.split()\n",
        "                if len(line) > 3:\n",
        "                    #label_set.append(line[3])\n",
        "                    if line[3] not in labels:\n",
        "                        remove = True\n",
        "                    else:\n",
        "                        pos_tag.append(line[1])\n",
        "                        chunk_tag.append(line[2])\n",
        "                    sentence.append((line[0],line[1],line[2],line[3]))\n",
        "                else:\n",
        "                    if len(sentence) > 0:\n",
        "                        if remove == False:                            \n",
        "                            all_data.append(sentence)\n",
        "                        else:\n",
        "                            remove = False\n",
        "                        sentence = []\n",
        "            f.close()\n",
        "\n",
        "    pos_tag = set(pos_tag)\n",
        "    chunk_tag = set(chunk_tag)\n",
        "    return  all_data, pos_tag, chunk_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ut2eUhP6TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_feature(word):\n",
        "    is_lower            = 'is_lower'\n",
        "    is_capital          = 'is_capital' \n",
        "    is_title            = 'is_title' \n",
        "    is_mix              = 'is_mix' \n",
        "    is_capital_period   = 'is_capital_period' \n",
        "    is_digit            = 'is_digit' \n",
        "    end_digit           = 'end_digit' \n",
        "    has_hyphen          = 'has_hyphen' \n",
        "    is_code             = 'is_code' \n",
        "    num_syllabus        = 'num_syllabus'\n",
        "    is_name             = 'is_name' \n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break;\n",
        "\n",
        "    ft = {\n",
        "        'bias'                : 1,\n",
        "        is_lower            : word.islower(),\n",
        "        is_capital          : word.isupper(),\n",
        "        is_title            : word.istitle(),\n",
        "        is_mix              : not(word.islower() and word.isupper()),\n",
        "        is_capital_period   : (('.' in word) and word[0].isupper()),\n",
        "        is_digit            : word.isdigit(),\n",
        "        end_digit           : word[-1].isdigit(),\n",
        "        has_hyphen          : ('-' in word),\n",
        "        is_code             : check_code,\n",
        "        num_syllabus        : (word.count('_') + 1),\n",
        "        is_name             : word[0].isupper()\n",
        "    }   \n",
        "    return ft\n",
        "\n",
        "def word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft):\n",
        "    word = sent[i][0]\n",
        "    ft = dict()\n",
        "    ### basic feature \n",
        "    # current word\n",
        "    ft['w0'] = word\n",
        "    # previous entity tag\n",
        "    ft['s-1'] = pre_state\n",
        "    ft['s-2'] = pre_pre_state\n",
        "    ### basic shape feature\n",
        "    ft.update(shape_feature(word))\n",
        "    ### basic joint feature\n",
        "    if i > 0:\n",
        "        ft['w-1'] = sent[i-1][0]\n",
        "    else:\n",
        "        ft['w-1'] = 'BOS'\n",
        "    \n",
        "    if i > 1:\n",
        "        ft['w-2'] = sent[i-2][0]\n",
        "    else:\n",
        "        ft['w-2'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['w+1'] = sent[i+1][0]#.replace('_', ' ')\n",
        "    else:\n",
        "        ft['w+1'] = 'EOS'\n",
        "    \n",
        "    if i < len(sent)-2:\n",
        "        ft['w+2'] = sent[i+2][0]\n",
        "    else:\n",
        "        ft['w+2'] = 'EOS'\n",
        "    ### regular expression type\n",
        "    ft['r0'] = sent_re_ft[i]\n",
        "    if i > 0:\n",
        "        ft['r-1'] = sent_re_ft[i-1]\n",
        "    else:\n",
        "        ft['r-1'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['r+1'] = sent_re_ft[i+1]\n",
        "    else:        \n",
        "        ft['r+1'] = 'EOS'\n",
        "    if i > 1:\n",
        "        ft['r-2'] = sent_re_ft[i-2]\n",
        "    else:\n",
        "        ft['r-2'] = 'BOS'\n",
        "    if i < len(sent)-2:\n",
        "        ft['r+2'] = sent_re_ft[i+2]\n",
        "    else:\n",
        "        ft['r+2'] = 'EOS'\n",
        "    ### extra joint feature\n",
        "    ft['w0+w-1'] = ft['w0'] + ' ' + ft['w-1']\n",
        "    ft['w0+w+1'] = ft['w0'] + ' ' + ft['w+1']\n",
        "    ft['w0+s-1'] = ft['w0'] + ' ' + ft['s-1']\n",
        "    ft['r0+r-1'] = ft['r0'] + ' ' + ft['r-1']\n",
        "    ft['r0+r+1'] = ft['r0'] + ' ' + ft['r+1']\n",
        "    ft['w0+r0']  = ft['w0'] + ' ' + ft['r0']\n",
        "    ft['w0+r-1'] = ft['w0'] + ' ' + ft['r-1']\n",
        "    ft['w0+r+1'] = ft['w0'] + ' ' + ft['r+1']\n",
        "    return ft\n",
        "re_adm_div      = ['ấp', 'buôn', 'bản', 'huyện', 'làng', 'miền', 'nước', \n",
        "                   'phường', 'quận', 'tỉnh', 'thành_phố', 'thị_trấn', 'thị_xã', \n",
        "                   'thôn', 'TT', 'TP', 'TX', 'TT.', 'TP.', 'TX.', 'xứ', 'xã', \n",
        "                   'xóm']\n",
        "re_org          = ['báo', 'bệnh_viện', 'bệnh_xá', 'công_ty', 'công_ti', 'đài', 'đảng', 'đoàn', 'hội', 'hợp_tác_xã', 'khách_sạn', 'nhà_máy', 'nhà_xuất_bản', 'ngân_hàng', 'quỹ', 'tạp_chí', 'tập đoàn', 'thông_tấn_xã', 'tờ', 'trạm_xá', 'xí_nghiệp','ủy_ban']\n",
        "re_school       = ['mẫu_giáo', 'tiểu_học', 'trung_học', 'trung_học_cơ_sở', \n",
        "                   'trung_học_phổ_thông', 'cao_đẳng', 'trung_cấp', \n",
        "                   'trung_cấp_nghề', 'đại_học']\n",
        "re_street       = ['đại_lộ', 'đường', 'hẻm', 'ngách', 'ngõ', 'nhà', 'phố', 'quốc_lộ']\n",
        "re_place        = ['ao', 'am', 'bến', 'bến_cảng', 'bến_phà','biển', 'cảng', \n",
        "                   'cầu', 'công_viên', 'chợ', 'chùa', 'dãy', 'đảo', 'đầm', 'đèo', \n",
        "                   'đền', 'đình', 'đồi', 'động', 'đồng_bằng', 'gềnh', 'gò', 'khu', 'hòn', 'hồ', \n",
        "                   'lăng', 'miếu', 'miền', 'nhà_ga', 'núi', 'phà', 'quần_đảo', \n",
        "                   'sân_bay', 'sông', 'suối', 'vùng']\n",
        "re_office       = ['ban', 'bộ', 'chi_cục', 'cục', 'hạt', 'sở']\n",
        "re_army         = ['binh_đoàn', 'đại_đội', 'đặc_khu', 'đơn_vị', 'lữ_đoàn', 'quân_đoàn', 'quân_đội', 'quân_khu','sư_đoàn', 'tiểu_đội', 'tiểu_đoàn', 'trung_đội']\n",
        "\n",
        "def re_word(word):\n",
        "    \"\"\"\n",
        "        Return a dict of (regexp Name, regexp Value) of a word\n",
        "        :type word: string\n",
        "        :param word: a word in sentence\n",
        "    \"\"\"\n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break\n",
        "\n",
        "    re_dict = dict()\n",
        "    re_dict['org'] = word.lower() in re_org\n",
        "    re_dict['name'] = word[0].isupper()\n",
        "    re_dict['capital'] = word.isupper()\n",
        "    re_dict['adm_div'] = word.lower() in re_adm_div\n",
        "    re_dict['is_school'] = word.lower() == 'trường'\n",
        "    re_dict['school'] = word.lower() in re_school\n",
        "    re_dict['street'] = word.lower() in re_street\n",
        "    re_dict['digit'] = word.isdigit()\n",
        "    re_dict['code'] = check_code\n",
        "    re_dict['place'] =  word in re_place\n",
        "    re_dict['office'] = word in re_office\n",
        "    re_dict['army'] = word in re_army\n",
        "    return re_dict \n",
        "\n",
        "re_type_name = [ \n",
        "    ('ofice_name_admdiv_name', ['office', 'name', 'adm_div', 'name']),\n",
        "    ('school_type_name_name'     , ['is_school', 'school', 'name', 'name']),\n",
        "    ('school_capital_name_name'  , ['is_school', 'capital', 'name', 'name']),\n",
        "    ('org_cap_name_name'         , ['org', 'capital', 'name', 'name']),\n",
        "    ('org_adm_div'          , ['capital', 'adm_div', 'name']),\n",
        "    ('school_type_name'     , ['is_school', 'school', 'name']),\n",
        "    ('school_capital_name'  , ['is_school', 'capital', 'name']),\n",
        "    ('org_cap_name'         , ['org', 'capital', 'name']),\n",
        "    ('place_name_name'           , ['place', 'name', 'name']),\n",
        "    ('place_name'           , ['place', 'name']),\n",
        "    ('org_name'                  , ['org', 'name', 'name']),\n",
        "    ('school_name_name'          , ['school', 'name', 'name']),\n",
        "    ('office_name_name'               , ['office', 'name', 'name']),\n",
        "    ('street_name_name'          , ['street', 'name', 'name']),\n",
        "    ('org'                  , ['org', 'name']),\n",
        "    ('school_name'          , ['school', 'name']),\n",
        "    ('adm_div'              , ['adm_div', 'name']),\n",
        "    ('office_name'               , ['office', 'name']),\n",
        "    ('street_name'          , ['street', 'name']),\n",
        "    ('street_digit'         , ['street', 'digit']),\n",
        "    ('street_code'          , ['street', 'code']),\n",
        "    ('army_name'            , ['army', 'code']),\n",
        "    ('army_name'            , ['army', 'digit']),\n",
        "    ('army_name'            , ['army', 'name'])\n",
        "]\n",
        "\n",
        "def sent_re_feature(sent):\n",
        "    l = len(sent)\n",
        "    sent_re_ft = ['NA'] * l\n",
        "    re_dict_word = [re_word(word[0]) for word in sent]\n",
        "    for type_name in re_type_name:\n",
        "        tl = len(type_name[1])\n",
        "        for i in range(l):\n",
        "            if (i + tl <= l):\n",
        "                if (set(['NA']) == set([sent_re_ft[i+j] for j in range(tl)])) and (set([True]) == set([re_dict_word[i+ll][type_name[1][ll]] for ll in range(tl)])):\n",
        "                    for k in range(tl):\n",
        "                        sent_re_ft[i+k] = type_name[0]\n",
        "    return sent_re_ft\n",
        "\n",
        "def sent_feature_train(sent):\n",
        "    sent_ft_train = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        if i < 1:\n",
        "            sent_ft_train.append((word_feature(sent, i, 'BOS', 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  len(labels)))\n",
        "        elif i < 2:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))\n",
        "        else:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], sent[i-2][3], sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))    \n",
        "    return sent_ft_train        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEpUrQIRwNQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_feature_test(sent, pre_state, pre_pre_state):\n",
        "    sent_ft_test = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        sent_ft_test.append(word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft))    \n",
        "    return sent_ft_test      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLUitkgW_14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_decoder(model, sent):\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    alpha = [([None] * len(labels)) for i in range(len(sent))]\n",
        "    trace = np.full(shape=(len(sent), len(labels)), fill_value=-1)\n",
        "\n",
        "    # start probability\n",
        "    pdist = model[len(labels)].prob_classify(word_feature(sent, 0, 'BOS', 'BOS', sent_re_ft))    \n",
        "    alpha[0] = [pdist.prob(l) for l in labels]\n",
        "    \n",
        "    for i in range(1, len(sent)):\n",
        "        alpha[i] = [0] * len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            pre_state = labels[j];\n",
        "            pre_pre_state = 'BOS'\n",
        "            if i > 1:\n",
        "                pre_pre_state = labels[trace[i-1][j]];\n",
        "            feature = word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft)\n",
        "            pdist = model[j].prob_classify(feature)                \n",
        "            posterior = [pdist.prob(l) for l in labels]\n",
        "            for k in range(len(labels)):\n",
        "                if alpha[i][k] < (posterior[k] * alpha[i-1][j]):\n",
        "                    alpha[i][k] = posterior[k] * alpha[i-1][j]\n",
        "                    trace[i][k] = j\n",
        "    m = alpha[-1][0]\n",
        "    idx = 0\n",
        "    for i in range(1, len(alpha[-1])):\n",
        "        if (alpha[-1][i] > m):\n",
        "            m = alpha[-1][i]\n",
        "            idx = i;\n",
        "    predict = list()\n",
        "    for i in range(len(sent)-1, -1, -1):\n",
        "        predict.append(labels[idx])\n",
        "        idx = trace[i][idx]\n",
        "    # print(alpha)\n",
        "    return reversed(predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0c_283RGcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sent(model, sent):\n",
        "    y_test_sent = [sent[i][3] for i in range(len(sent))]   \n",
        "    y_pred_sent = viterbi_decoder(model, sent)\n",
        "    return y_test_sent, y_pred_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrrICItK-LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, sents):\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for sent in sents:\n",
        "        test, pred = predict_sent(model, sent)\n",
        "        y_test.extend(test)\n",
        "        y_pred.extend(pred)\n",
        "    return y_test, y_pred            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDuKHtwrqIFM",
        "colab_type": "code",
        "outputId": "2078fe8f-82e8-4492-8b61-7b2cb80501c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_data, pos_tag, chunk_tag = prepare_data(data_path)\n",
        "train_sents, test_sents = train_test_split(all_data, test_size = 0.15, random_state=42)\n",
        "print(\"train_sents\", len(train_sents))\n",
        "print(\"test_sents\", len(test_sents))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents 14087\n",
            "test_sents 2486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1EC8jzHu-P",
        "colab_type": "code",
        "outputId": "e299fd98-2c32-4b97-8f27-e99ce15bdb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "train_data = [[] for i in range(len(labels) + 1)]\n",
        "for sent in train_sents:\n",
        "    for feature, label, pre_label in sent_feature_train(sent):\n",
        "        train_data[pre_label].append((feature, labels[label]))     \n",
        "\n",
        "for i in range(len(labels) + 1):\n",
        "    print('train_data[' + str(i) +'] length', len(train_data[i]))\n",
        "    print(train_data[i][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data[0] length 6259\n",
            "({'w0': 'về', 's-1': 'B-PER', 's-2': 'O', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Phong', 'w-2': 'ông', 'w+1': 'Thái_Bình', 'w+2': 'thăm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA', 'w0+w-1': 'về Phong', 'w0+w+1': 'về Thái_Bình', 'w0+s-1': 'về B-PER', 'r0+r-1': 'NA NA', 'r0+r+1': 'NA NA', 'w0+r0': 'về NA', 'w0+r-1': 'về NA', 'w0+r+1': 'về NA'}, 'O')\n",
            "train_data[1] length 2899\n",
            "({'w0': 'Bình', 's-1': 'I-PER', 's-2': 'B-PER', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trọng', 'w-2': 'Hồ', 'w+1': 'nói', 'w+2': ':', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA', 'w0+w-1': 'Bình Trọng', 'w0+w+1': 'Bình nói', 'w0+s-1': 'Bình I-PER', 'r0+r-1': 'NA NA', 'r0+r+1': 'NA NA', 'w0+r0': 'Bình NA', 'w0+r-1': 'Bình NA', 'w0+r+1': 'Bình NA'}, 'I-PER')\n",
            "train_data[2] length 991\n",
            "({'w0': 'Kredtrakarn', 's-1': 'B-ORG', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trung_tâm', 'w-2': 'BOS', 'w+1': 'đang', 'w+2': 'tìm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA', 'w0+w-1': 'Kredtrakarn Trung_tâm', 'w0+w+1': 'Kredtrakarn đang', 'w0+s-1': 'Kredtrakarn B-ORG', 'r0+r-1': 'NA NA', 'r0+r+1': 'NA NA', 'w0+r0': 'Kredtrakarn NA', 'w0+r-1': 'Kredtrakarn NA', 'w0+r+1': 'Kredtrakarn NA'}, 'I-ORG')\n",
            "train_data[3] length 1675\n",
            "({'w0': 'đang', 's-1': 'I-ORG', 's-2': 'B-ORG', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Kredtrakarn', 'w-2': 'Trung_tâm', 'w+1': 'tìm', 'w+2': 'địa_chỉ', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA', 'w0+w-1': 'đang Kredtrakarn', 'w0+w+1': 'đang tìm', 'w0+s-1': 'đang I-ORG', 'r0+r-1': 'NA NA', 'r0+r+1': 'NA NA', 'w0+r0': 'đang NA', 'w0+r-1': 'đang NA', 'w0+r+1': 'đang NA'}, 'O')\n",
            "train_data[4] length 5090\n",
            "({'w0': 'Mai', 's-1': 'B-LOC', 's-2': 'O', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'chợ', 'w-2': 'ở', 'w+1': 'Xuân', 'w+2': 'Thưởng', 'r0': 'place_name_name', 'r-1': 'place_name_name', 'r+1': 'place_name_name', 'r-2': 'NA', 'r+2': 'NA', 'w0+w-1': 'Mai chợ', 'w0+w+1': 'Mai Xuân', 'w0+s-1': 'Mai B-LOC', 'r0+r-1': 'place_name_name place_name_name', 'r0+r+1': 'place_name_name place_name_name', 'w0+r0': 'Mai place_name_name', 'w0+r-1': 'Mai place_name_name', 'w0+r+1': 'Mai place_name_name'}, 'I-LOC')\n",
            "train_data[5] length 2302\n",
            "({'w0': 'Xuân', 's-1': 'I-LOC', 's-2': 'B-LOC', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Mai', 'w-2': 'chợ', 'w+1': 'Thưởng', 'w+2': 'sẽ', 'r0': 'place_name_name', 'r-1': 'place_name_name', 'r+1': 'NA', 'r-2': 'place_name_name', 'r+2': 'NA', 'w0+w-1': 'Xuân Mai', 'w0+w+1': 'Xuân Thưởng', 'w0+s-1': 'Xuân I-LOC', 'r0+r-1': 'place_name_name place_name_name', 'r0+r+1': 'place_name_name NA', 'w0+r0': 'Xuân place_name_name', 'w0+r-1': 'Xuân place_name_name', 'w0+r+1': 'Xuân NA'}, 'I-LOC')\n",
            "train_data[6] length 272497\n",
            "({'w0': 'một_số', 's-1': 'O', 's-2': 'BOS', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 2, 'is_name': False, 'w-1': 'Ngoài', 'w-2': 'BOS', 'w+1': 'nhỏ', 'w+2': 'gồm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA', 'w0+w-1': 'một_số Ngoài', 'w0+w+1': 'một_số nhỏ', 'w0+s-1': 'một_số O', 'r0+r-1': 'NA NA', 'r0+r+1': 'NA NA', 'w0+r0': 'một_số NA', 'w0+r-1': 'một_số NA', 'w0+r+1': 'một_số NA'}, 'O')\n",
            "train_data[7] length 14087\n",
            "({'w0': 'Ngoài', 's-1': 'BOS', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'BOS', 'w-2': 'BOS', 'w+1': 'một_số', 'w+2': 'nhỏ', 'r0': 'NA', 'r-1': 'BOS', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA', 'w0+w-1': 'Ngoài BOS', 'w0+w+1': 'Ngoài một_số', 'w0+s-1': 'Ngoài BOS', 'r0+r-1': 'NA BOS', 'r0+r+1': 'NA NA', 'w0+r0': 'Ngoài NA', 'w0+r-1': 'Ngoài BOS', 'w0+r+1': 'Ngoài NA'}, 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DOocaPDqL4n",
        "colab_type": "code",
        "outputId": "22c225b0-05d6-4b3d-8477-026548164743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time \n",
        "max_iter = 10\n",
        "model = [[] for i in range(len(labels) + 1)]\n",
        "for i in range(len(labels) + 1):\n",
        "    if i == 6:\n",
        "        continue\n",
        "    print(\"Training with pre_state\", i)\n",
        "    encoding = BinaryMaxentFeatureEncoding.train(train_data[i], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "    model[i]= MaxentClassifier.train(train_data[i], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "print(\"Training with pre_state\", 6)\n",
        "encoding_ = BinaryMaxentFeatureEncoding.train(train_data[6], count_cutoff=4, labels = labels, alwayson_features=True)\n",
        "model[6] = MaxentClassifier.train(train_data[6], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-multi-classifier-featureset3-binaryfeature-maxiter10.model\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with pre_state 0\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.714\n",
            "             2          -0.31826        0.923\n",
            "             3          -0.20834        0.987\n",
            "             4          -0.14433        0.988\n",
            "             5          -0.10556        0.990\n",
            "             6          -0.08088        0.990\n",
            "             7          -0.06443        0.991\n",
            "             8          -0.05301        0.991\n",
            "             9          -0.04482        0.992\n",
            "         Final          -0.03876        0.993\n",
            "Training with pre_state 1\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.614\n",
            "             2          -0.39534        0.962\n",
            "             3          -0.26964        0.964\n",
            "             4          -0.19779        0.968\n",
            "             5          -0.15380        0.972\n",
            "             6          -0.12509        0.973\n",
            "             7          -0.10532        0.979\n",
            "             8          -0.09107        0.982\n",
            "             9          -0.08041        0.984\n",
            "         Final          -0.07219        0.985\n",
            "Training with pre_state 2\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.222\n",
            "             2          -0.34515        0.773\n",
            "             3          -0.29304        0.815\n",
            "             4          -0.25641        0.904\n",
            "             5          -0.22873        0.926\n",
            "             6          -0.20732        0.940\n",
            "             7          -0.19037        0.958\n",
            "             8          -0.17667        0.965\n",
            "             9          -0.16538        0.967\n",
            "         Final          -0.15595        0.965\n",
            "Training with pre_state 3\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.436\n",
            "             2          -0.53015        0.922\n",
            "             3          -0.45285        0.915\n",
            "             4          -0.40074        0.915\n",
            "             5          -0.36315        0.918\n",
            "             6          -0.33451        0.918\n",
            "             7          -0.31178        0.921\n",
            "             8          -0.29319        0.922\n",
            "             9          -0.27766        0.924\n",
            "         Final          -0.26445        0.925\n",
            "Training with pre_state 4\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.60944        0.626\n",
            "             2          -0.36129        0.959\n",
            "             3          -0.25766        0.970\n",
            "             4          -0.19863        0.972\n",
            "             5          -0.16152        0.973\n",
            "             6          -0.13641        0.974\n",
            "             7          -0.11847        0.976\n",
            "             8          -0.10510        0.978\n",
            "             9          -0.09478        0.979\n",
            "         Final          -0.08662        0.980\n",
            "Training with pre_state 5\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.818\n",
            "             2          -0.25757        0.830\n",
            "             3          -0.19991        0.925\n",
            "             4          -0.16170        0.960\n",
            "             5          -0.13559        0.967\n",
            "             6          -0.11699        0.973\n",
            "             7          -0.10320        0.975\n",
            "             8          -0.09263        0.976\n",
            "             9          -0.08431        0.977\n",
            "         Final          -0.07762        0.978\n",
            "Training with pre_state 7\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.937\n",
            "             2          -0.12214        0.937\n",
            "             3          -0.11640        0.937\n",
            "             4          -0.11038        0.938\n",
            "             5          -0.10414        0.939\n",
            "             6          -0.09829        0.941\n",
            "             7          -0.09304        0.943\n",
            "             8          -0.08840        0.945\n",
            "             9          -0.08431        0.952\n",
            "         Final          -0.08071        0.958\n",
            "Training with pre_state 6\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94285        0.958\n",
            "             2          -0.07650        0.960\n",
            "             3          -0.07168        0.960\n",
            "             4          -0.06708        0.960\n",
            "             5          -0.06193        0.962\n",
            "             6          -0.05718        0.966\n",
            "             7          -0.05310        0.971\n",
            "             8          -0.04969        0.973\n",
            "             9          -0.04684        0.974\n",
            "         Final          -0.04445        0.975\n",
            "CPU times: user 32min, sys: 4.55 s, total: 32min 4s\n",
            "Wall time: 32min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80hkGhIOBlua",
        "colab_type": "code",
        "outputId": "2938f601-268b-4fdb-8ade-d185a55939ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-multi-classifier-featureset3-binaryfeature-maxiter10.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['81.97%', '88.03%', '75.31%', '81.44%', '74.42%', '77.78%']\n",
            "recall:    ['65.37%', '82.51%', '20.71%', '31.34%', '19.39%', '16.84%']\n",
            "fscore:    ['72.74%', '85.18%', '32.49%', '45.26%', '30.77%', '27.68%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 80.39%\n",
            "total recall (weighted): 45.54%\n",
            "total fscore (weighted): 54.67%\n",
            "CPU times: user 1min 6s, sys: 46.8 ms, total: 1min 6s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iFAxKxnMKEM",
        "colab_type": "code",
        "outputId": "7b01f1b1-bd4a-4d6f-d73e-d88cf8eb72c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('model 0______________________________________________________')\n",
        "test_model[0].show_most_informative_features()\n",
        "print('model 1______________________________________________________')\n",
        "test_model[1].show_most_informative_features()\n",
        "print('model 2______________________________________________________')\n",
        "test_model[2].show_most_informative_features()\n",
        "print('model 3______________________________________________________')\n",
        "test_model[3].show_most_informative_features()\n",
        "print('model 4______________________________________________________')\n",
        "test_model[4].show_most_informative_features()\n",
        "print('model 5______________________________________________________')\n",
        "test_model[5].show_most_informative_features()\n",
        "print('model 6______________________________________________________')\n",
        "test_model[6].show_most_informative_features()\n",
        "print('model 7______________________________________________________')\n",
        "test_model[7].show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model 0 ______________________________________________________\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'B-LOC'\n",
            "    -inf label is 'I-LOC'\n",
            "  -2.209 is_title==True and label is 'O'\n",
            "  -2.013 is_name==True and label is 'O'\n",
            "  -1.733 is_lower==True and label is 'I-PER'\n",
            "  -1.041 has_hyphen==True and label is 'I-PER'\n",
            "  -1.015 num_syllabus==2 and label is 'I-PER'\n",
            "  -1.010 w-1=='Chương' and label is 'I-PER'\n",
            "model 1______________________________________________________\n",
            "    -inf label is 'B-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "  -2.500 is_title==True and label is 'O'\n",
            "   2.415 w-2=='Lý' and label is 'B-LOC'\n",
            "  -1.949 is_name==True and label is 'O'\n",
            "   1.813 w+2==':' and label is 'B-LOC'\n",
            "  -1.119 w-2=='Văn' and label is 'I-PER'\n",
            "  -1.109 w+2=='tuổi' and label is 'I-PER'\n",
            "model 2______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "   1.895 w-2=='thuộc' and label is 'I-LOC'\n",
            "  -1.891 is_name==True and label is 'O'\n",
            "  -1.693 is_title==True and label is 'O'\n",
            "   1.662 has_hyphen==True and label is 'B-ORG'\n",
            "   1.654 w+1=='và' and label is 'I-LOC'\n",
            "   1.519 num_syllabus==3 and label is 'B-LOC'\n",
            "   1.317 is_digit==True and label is 'I-LOC'\n",
            "  -1.290 r+1=='org_adm_div' and label is 'O'\n",
            "  -1.282 is_capital==True and label is 'O'\n",
            "model 3______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "   1.567 w-2=='về' and label is 'B-ORG'\n",
            "   1.552 w0=='Thái' and label is 'I-LOC'\n",
            "   1.552 w0+s-1=='Thái I-ORG' and label is 'I-LOC'\n",
            "   1.552 w0+r0=='Thái NA' and label is 'I-LOC'\n",
            "   1.552 w0+r-1=='Thái NA' and label is 'I-LOC'\n",
            "   1.552 w0+r+1=='Thái NA' and label is 'I-LOC'\n",
            "   1.504 w-1=='ma_tuý' and label is 'B-ORG'\n",
            "   1.434 w-2=='và' and label is 'B-ORG'\n",
            "   1.310 w-1=='môi_trường' and label is 'B-PER'\n",
            "model 4______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "   2.404 w-1=='Hàn_Quốc' and label is 'B-ORG'\n",
            "  -2.346 is_title==True and label is 'O'\n",
            "  -2.271 is_name==True and label is 'O'\n",
            "   2.132 w+2=='với' and label is 'B-ORG'\n",
            "   2.058 w+1=='...' and label is 'B-ORG'\n",
            "   1.909 w-2=='bạn' and label is 'B-PER'\n",
            "   1.748 w+1=='đổ' and label is 'B-LOC'\n",
            "   1.692 w+1=='Thị' and label is 'B-PER'\n",
            "model 5______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "   2.064 w+1=='Văn' and label is 'B-PER'\n",
            "   1.823 w0=='Lê' and label is 'B-PER'\n",
            "   1.823 w0+s-1=='Lê I-LOC' and label is 'B-PER'\n",
            "  -1.701 is_title==True and label is 'O'\n",
            "   1.570 w-1=='Thống_Nhất' and label is 'B-LOC'\n",
            "  -1.519 is_name==True and label is 'O'\n",
            "   1.371 r+1=='street_digit' and label is 'B-LOC'\n",
            "model 6______________________________________________________\n",
            "    -inf s-1=='BOS' and label is 'O'\n",
            "    -inf w-1=='BOS' and label is 'O'\n",
            "    -inf r-1=='BOS' and label is 'O'\n",
            "    -inf r0+r-1=='NA BOS' and label is 'O'\n",
            "    -inf s-1=='BOS' and label is 'B-ORG'\n",
            "    -inf w-1=='BOS' and label is 'B-ORG'\n",
            "    -inf r-1=='BOS' and label is 'B-ORG'\n",
            "    -inf r0+r-1=='NA BOS' and label is 'B-ORG'\n",
            "    -inf s-1=='BOS' and label is 'B-PER'\n",
            "    -inf w-1=='BOS' and label is 'B-PER'\n",
            "model 7______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   1.921 w+2=='thế_giới' and label is 'B-ORG'\n",
            "   1.840 w+1=='Sài_Gòn' and label is 'B-ORG'\n",
            "   1.491 w+2=='thuyền' and label is 'B-LOC'\n",
            "   1.437 w+1=='xác_định' and label is 'B-LOC'\n",
            "   1.412 w+2=='đầy' and label is 'B-LOC'\n",
            "   1.401 w+2=='một_số' and label is 'B-LOC'\n",
            "   1.374 w+1=='nằm' and label is 'B-LOC'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kexgU6RTQ4zu",
        "colab_type": "code",
        "outputId": "ae8d852a-54ac-40b8-a5fd-53a0c6d808f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time \n",
        "max_iter = 50\n",
        "model = [[] for i in range(len(labels) + 1)]\n",
        "for i in range(len(labels) + 1):\n",
        "    if i == 6:\n",
        "        continue\n",
        "    print(\"Training with pre_state\", i)\n",
        "    encoding = BinaryMaxentFeatureEncoding.train(train_data[i], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "    model[i]= MaxentClassifier.train(train_data[i], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "print(\"Training with pre_state\", 6)\n",
        "encoding_ = BinaryMaxentFeatureEncoding.train(train_data[6], count_cutoff=4, labels = labels, alwayson_features=True)\n",
        "model[6] = MaxentClassifier.train(train_data[6], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-multi-classifier-featureset3-binaryfeature-maxiter50.model\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.714\n",
            "             2          -0.31826        0.923\n",
            "             3          -0.20834        0.987\n",
            "             4          -0.14433        0.988\n",
            "             5          -0.10556        0.990\n",
            "             6          -0.08088        0.990\n",
            "             7          -0.06443        0.991\n",
            "             8          -0.05301        0.991\n",
            "             9          -0.04482        0.992\n",
            "            10          -0.03876        0.993\n",
            "            11          -0.03415        0.993\n",
            "            12          -0.03058        0.993\n",
            "            13          -0.02774        0.993\n",
            "            14          -0.02546        0.994\n",
            "            15          -0.02358        0.994\n",
            "            16          -0.02203        0.994\n",
            "            17          -0.02071        0.994\n",
            "            18          -0.01960        0.994\n",
            "            19          -0.01864        0.995\n",
            "            20          -0.01781        0.995\n",
            "            21          -0.01708        0.995\n",
            "            22          -0.01644        0.995\n",
            "            23          -0.01587        0.996\n",
            "            24          -0.01536        0.996\n",
            "            25          -0.01490        0.996\n",
            "            26          -0.01448        0.996\n",
            "            27          -0.01411        0.996\n",
            "            28          -0.01377        0.996\n",
            "            29          -0.01345        0.996\n",
            "            30          -0.01317        0.996\n",
            "            31          -0.01290        0.996\n",
            "            32          -0.01265        0.996\n",
            "            33          -0.01242        0.996\n",
            "            34          -0.01221        0.996\n",
            "            35          -0.01201        0.996\n",
            "            36          -0.01183        0.996\n",
            "            37          -0.01165        0.996\n",
            "            38          -0.01149        0.996\n",
            "            39          -0.01133        0.996\n",
            "            40          -0.01118        0.997\n",
            "            41          -0.01105        0.997\n",
            "            42          -0.01091        0.997\n",
            "            43          -0.01079        0.997\n",
            "            44          -0.01067        0.997\n",
            "            45          -0.01055        0.997\n",
            "            46          -0.01045        0.997\n",
            "            47          -0.01034        0.997\n",
            "            48          -0.01024        0.997\n",
            "            49          -0.01015        0.997\n",
            "         Final          -0.01006        0.997\n",
            "Training with pre_state 1\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.614\n",
            "             2          -0.39534        0.962\n",
            "             3          -0.26964        0.964\n",
            "             4          -0.19779        0.968\n",
            "             5          -0.15380        0.972\n",
            "             6          -0.12509        0.973\n",
            "             7          -0.10532        0.979\n",
            "             8          -0.09107        0.982\n",
            "             9          -0.08041        0.984\n",
            "            10          -0.07219        0.985\n",
            "            11          -0.06568        0.986\n",
            "            12          -0.06041        0.986\n",
            "            13          -0.05607        0.987\n",
            "            14          -0.05243        0.988\n",
            "            15          -0.04933        0.989\n",
            "            16          -0.04667        0.989\n",
            "            17          -0.04436        0.990\n",
            "            18          -0.04233        0.990\n",
            "            19          -0.04053        0.990\n",
            "            20          -0.03892        0.991\n",
            "            21          -0.03747        0.991\n",
            "            22          -0.03616        0.991\n",
            "            23          -0.03497        0.991\n",
            "            24          -0.03388        0.991\n",
            "            25          -0.03288        0.991\n",
            "            26          -0.03196        0.991\n",
            "            27          -0.03110        0.992\n",
            "            28          -0.03030        0.992\n",
            "            29          -0.02955        0.992\n",
            "            30          -0.02886        0.992\n",
            "            31          -0.02820        0.992\n",
            "            32          -0.02758        0.992\n",
            "            33          -0.02700        0.992\n",
            "            34          -0.02645        0.993\n",
            "            35          -0.02592        0.993\n",
            "            36          -0.02542        0.994\n",
            "            37          -0.02495        0.994\n",
            "            38          -0.02450        0.994\n",
            "            39          -0.02407        0.994\n",
            "            40          -0.02365        0.994\n",
            "            41          -0.02326        0.994\n",
            "            42          -0.02288        0.994\n",
            "            43          -0.02252        0.994\n",
            "            44          -0.02217        0.994\n",
            "            45          -0.02183        0.994\n",
            "            46          -0.02151        0.994\n",
            "            47          -0.02120        0.994\n",
            "            48          -0.02090        0.994\n",
            "            49          -0.02060        0.994\n",
            "         Final          -0.02032        0.994\n",
            "Training with pre_state 2\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.222\n",
            "             2          -0.34515        0.773\n",
            "             3          -0.29304        0.815\n",
            "             4          -0.25641        0.904\n",
            "             5          -0.22873        0.926\n",
            "             6          -0.20732        0.940\n",
            "             7          -0.19037        0.958\n",
            "             8          -0.17667        0.965\n",
            "             9          -0.16538        0.967\n",
            "            10          -0.15595        0.965\n",
            "            11          -0.14794        0.966\n",
            "            12          -0.14106        0.964\n",
            "            13          -0.13508        0.964\n",
            "            14          -0.12984        0.963\n",
            "            15          -0.12521        0.963\n",
            "            16          -0.12107        0.964\n",
            "            17          -0.11736        0.964\n",
            "            18          -0.11401        0.964\n",
            "            19          -0.11096        0.964\n",
            "            20          -0.10818        0.964\n",
            "            21          -0.10562        0.963\n",
            "            22          -0.10327        0.963\n",
            "            23          -0.10109        0.963\n",
            "            24          -0.09907        0.963\n",
            "            25          -0.09718        0.963\n",
            "            26          -0.09542        0.964\n",
            "            27          -0.09377        0.965\n",
            "            28          -0.09222        0.965\n",
            "            29          -0.09076        0.965\n",
            "            30          -0.08939        0.965\n",
            "            31          -0.08809        0.966\n",
            "            32          -0.08685        0.967\n",
            "            33          -0.08568        0.968\n",
            "            34          -0.08457        0.968\n",
            "            35          -0.08351        0.968\n",
            "            36          -0.08249        0.968\n",
            "            37          -0.08153        0.968\n",
            "            38          -0.08060        0.968\n",
            "            39          -0.07972        0.968\n",
            "            40          -0.07887        0.968\n",
            "            41          -0.07805        0.968\n",
            "            42          -0.07727        0.968\n",
            "            43          -0.07652        0.969\n",
            "            44          -0.07579        0.969\n",
            "            45          -0.07509        0.969\n",
            "            46          -0.07441        0.969\n",
            "            47          -0.07376        0.971\n",
            "            48          -0.07313        0.971\n",
            "            49          -0.07252        0.971\n",
            "         Final          -0.07193        0.971\n",
            "Training with pre_state 3\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.436\n",
            "             2          -0.53015        0.922\n",
            "             3          -0.45285        0.915\n",
            "             4          -0.40074        0.915\n",
            "             5          -0.36315        0.918\n",
            "             6          -0.33451        0.918\n",
            "             7          -0.31178        0.921\n",
            "             8          -0.29319        0.922\n",
            "             9          -0.27766        0.924\n",
            "            10          -0.26445        0.925\n",
            "            11          -0.25304        0.929\n",
            "            12          -0.24307        0.930\n",
            "            13          -0.23427        0.932\n",
            "            14          -0.22642        0.936\n",
            "            15          -0.21938        0.938\n",
            "            16          -0.21301        0.939\n",
            "            17          -0.20721        0.940\n",
            "            18          -0.20191        0.940\n",
            "            19          -0.19703        0.940\n",
            "            20          -0.19253        0.940\n",
            "            21          -0.18835        0.941\n",
            "            22          -0.18446        0.941\n",
            "            23          -0.18083        0.943\n",
            "            24          -0.17743        0.944\n",
            "            25          -0.17424        0.945\n",
            "            26          -0.17123        0.946\n",
            "            27          -0.16838        0.948\n",
            "            28          -0.16569        0.949\n",
            "            29          -0.16314        0.949\n",
            "            30          -0.16072        0.949\n",
            "            31          -0.15841        0.950\n",
            "            32          -0.15621        0.952\n",
            "            33          -0.15411        0.952\n",
            "            34          -0.15210        0.952\n",
            "            35          -0.15018        0.952\n",
            "            36          -0.14833        0.953\n",
            "            37          -0.14656        0.953\n",
            "            38          -0.14486        0.955\n",
            "            39          -0.14322        0.955\n",
            "            40          -0.14164        0.956\n",
            "            41          -0.14011        0.958\n",
            "            42          -0.13864        0.958\n",
            "            43          -0.13722        0.958\n",
            "            44          -0.13585        0.958\n",
            "            45          -0.13452        0.958\n",
            "            46          -0.13323        0.959\n",
            "            47          -0.13198        0.959\n",
            "            48          -0.13077        0.960\n",
            "            49          -0.12960        0.960\n",
            "         Final          -0.12846        0.961\n",
            "Training with pre_state 4\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.60944        0.626\n",
            "             2          -0.36129        0.959\n",
            "             3          -0.25766        0.970\n",
            "             4          -0.19863        0.972\n",
            "             5          -0.16152        0.973\n",
            "             6          -0.13641        0.974\n",
            "             7          -0.11847        0.976\n",
            "             8          -0.10510        0.978\n",
            "             9          -0.09478        0.979\n",
            "            10          -0.08662        0.980\n",
            "            11          -0.08001        0.980\n",
            "            12          -0.07456        0.981\n",
            "            13          -0.06998        0.982\n",
            "            14          -0.06610        0.983\n",
            "            15          -0.06276        0.983\n",
            "            16          -0.05985        0.984\n",
            "            17          -0.05730        0.984\n",
            "            18          -0.05504        0.985\n",
            "            19          -0.05303        0.985\n",
            "            20          -0.05122        0.985\n",
            "            21          -0.04959        0.985\n",
            "            22          -0.04811        0.985\n",
            "            23          -0.04676        0.986\n",
            "            24          -0.04552        0.986\n",
            "            25          -0.04438        0.986\n",
            "            26          -0.04333        0.986\n",
            "            27          -0.04235        0.986\n",
            "            28          -0.04144        0.986\n",
            "            29          -0.04059        0.987\n",
            "            30          -0.03979        0.987\n",
            "            31          -0.03905        0.987\n",
            "            32          -0.03835        0.988\n",
            "            33          -0.03769        0.988\n",
            "            34          -0.03706        0.988\n",
            "            35          -0.03647        0.988\n",
            "            36          -0.03591        0.988\n",
            "            37          -0.03538        0.988\n",
            "            38          -0.03487        0.988\n",
            "            39          -0.03439        0.988\n",
            "            40          -0.03393        0.988\n",
            "            41          -0.03348        0.988\n",
            "            42          -0.03306        0.988\n",
            "            43          -0.03266        0.988\n",
            "            44          -0.03227        0.988\n",
            "            45          -0.03190        0.988\n",
            "            46          -0.03154        0.988\n",
            "            47          -0.03119        0.988\n",
            "            48          -0.03086        0.988\n",
            "            49          -0.03054        0.989\n",
            "         Final          -0.03023        0.989\n",
            "Training with pre_state 5\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.818\n",
            "             2          -0.25757        0.830\n",
            "             3          -0.19991        0.925\n",
            "             4          -0.16170        0.960\n",
            "             5          -0.13559        0.967\n",
            "             6          -0.11699        0.973\n",
            "             7          -0.10320        0.975\n",
            "             8          -0.09263        0.976\n",
            "             9          -0.08431        0.977\n",
            "            10          -0.07762        0.978\n",
            "            11          -0.07214        0.978\n",
            "            12          -0.06759        0.979\n",
            "            13          -0.06375        0.980\n",
            "            14          -0.06048        0.980\n",
            "            15          -0.05767        0.980\n",
            "            16          -0.05523        0.981\n",
            "            17          -0.05308        0.981\n",
            "            18          -0.05119        0.982\n",
            "            19          -0.04951        0.982\n",
            "            20          -0.04800        0.982\n",
            "            21          -0.04664        0.983\n",
            "            22          -0.04541        0.983\n",
            "            23          -0.04428        0.983\n",
            "            24          -0.04326        0.983\n",
            "            25          -0.04231        0.983\n",
            "            26          -0.04144        0.983\n",
            "            27          -0.04064        0.984\n",
            "            28          -0.03989        0.984\n",
            "            29          -0.03919        0.985\n",
            "            30          -0.03853        0.986\n",
            "            31          -0.03792        0.986\n",
            "            32          -0.03734        0.987\n",
            "            33          -0.03680        0.987\n",
            "            34          -0.03628        0.987\n",
            "            35          -0.03579        0.987\n",
            "            36          -0.03533        0.987\n",
            "            37          -0.03489        0.987\n",
            "            38          -0.03447        0.987\n",
            "            39          -0.03407        0.987\n",
            "            40          -0.03369        0.987\n",
            "            41          -0.03333        0.987\n",
            "            42          -0.03298        0.987\n",
            "            43          -0.03264        0.987\n",
            "            44          -0.03232        0.987\n",
            "            45          -0.03201        0.987\n",
            "            46          -0.03171        0.988\n",
            "            47          -0.03142        0.988\n",
            "            48          -0.03114        0.988\n",
            "            49          -0.03087        0.988\n",
            "         Final          -0.03061        0.988\n",
            "Training with pre_state 7\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.937\n",
            "             2          -0.12214        0.937\n",
            "             3          -0.11640        0.937\n",
            "             4          -0.11038        0.938\n",
            "             5          -0.10414        0.939\n",
            "             6          -0.09829        0.941\n",
            "             7          -0.09304        0.943\n",
            "             8          -0.08840        0.945\n",
            "             9          -0.08431        0.952\n",
            "            10          -0.08071        0.958\n",
            "            11          -0.07752        0.964\n",
            "            12          -0.07468        0.969\n",
            "            13          -0.07214        0.973\n",
            "            14          -0.06986        0.975\n",
            "            15          -0.06780        0.977\n",
            "            16          -0.06593        0.978\n",
            "            17          -0.06423        0.979\n",
            "            18          -0.06267        0.980\n",
            "            19          -0.06123        0.980\n",
            "            20          -0.05990        0.980\n",
            "            21          -0.05868        0.981\n",
            "            22          -0.05753        0.981\n",
            "            23          -0.05647        0.981\n",
            "            24          -0.05547        0.981\n",
            "            25          -0.05453        0.981\n",
            "            26          -0.05365        0.981\n",
            "            27          -0.05282        0.981\n",
            "            28          -0.05203        0.982\n",
            "            29          -0.05129        0.982\n",
            "            30          -0.05058        0.982\n",
            "            31          -0.04991        0.982\n",
            "            32          -0.04927        0.982\n",
            "            33          -0.04866        0.982\n",
            "            34          -0.04808        0.982\n",
            "            35          -0.04753        0.982\n",
            "            36          -0.04699        0.982\n",
            "            37          -0.04648        0.983\n",
            "            38          -0.04599        0.983\n",
            "            39          -0.04552        0.983\n",
            "            40          -0.04507        0.983\n",
            "            41          -0.04463        0.983\n",
            "            42          -0.04421        0.983\n",
            "            43          -0.04381        0.983\n",
            "            44          -0.04342        0.983\n",
            "            45          -0.04304        0.983\n",
            "            46          -0.04268        0.983\n",
            "            47          -0.04232        0.983\n",
            "            48          -0.04198        0.983\n",
            "            49          -0.04165        0.984\n",
            "         Final          -0.04133        0.984\n",
            "Training with pre_state 6\n",
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94285        0.958\n",
            "             2          -0.07650        0.960\n",
            "             3          -0.07168        0.960\n",
            "             4          -0.06708        0.960\n",
            "             5          -0.06193        0.962\n",
            "             6          -0.05718        0.966\n",
            "             7          -0.05310        0.971\n",
            "             8          -0.04969        0.973\n",
            "             9          -0.04684        0.974\n",
            "            10          -0.04445        0.975\n",
            "            11          -0.04242        0.976\n",
            "            12          -0.04069        0.977\n",
            "            13          -0.03920        0.977\n",
            "            14          -0.03790        0.978\n",
            "            15          -0.03677        0.980\n",
            "            16          -0.03576        0.981\n",
            "            17          -0.03487        0.982\n",
            "            18          -0.03407        0.983\n",
            "            19          -0.03334        0.985\n",
            "            20          -0.03269        0.985\n",
            "            21          -0.03209        0.985\n",
            "            22          -0.03155        0.986\n",
            "            23          -0.03105        0.986\n",
            "            24          -0.03059        0.986\n",
            "            25          -0.03016        0.986\n",
            "            26          -0.02976        0.986\n",
            "            27          -0.02939        0.986\n",
            "            28          -0.02905        0.986\n",
            "            29          -0.02872        0.986\n",
            "            30          -0.02842        0.986\n",
            "            31          -0.02814        0.986\n",
            "            32          -0.02787        0.986\n",
            "            33          -0.02761        0.986\n",
            "            34          -0.02737        0.987\n",
            "            35          -0.02715        0.987\n",
            "            36          -0.02693        0.987\n",
            "            37          -0.02672        0.987\n",
            "            38          -0.02653        0.987\n",
            "            39          -0.02634        0.987\n",
            "            40          -0.02617        0.987\n",
            "            41          -0.02600        0.987\n",
            "            42          -0.02583        0.987\n",
            "            43          -0.02568        0.987\n",
            "            44          -0.02553        0.987\n",
            "            45          -0.02539        0.987\n",
            "            46          -0.02525        0.987\n",
            "            47          -0.02512        0.987\n",
            "            48          -0.02499        0.987\n",
            "            49          -0.02487        0.987\n",
            "         Final          -0.02475        0.987\n",
            "CPU times: user 2h 47min 19s, sys: 31.3 s, total: 2h 47min 50s\n",
            "Wall time: 2h 48min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1NJ-DW-Q9_e",
        "colab_type": "code",
        "outputId": "bd605b86-31cb-4de9-a239-29d62ec85816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-multi-classifier-featureset3-binaryfeature-maxiter50.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['74.94%', '85.84%', '69.44%', '71.67%', '68.57%', '73.95%']\n",
            "recall:    ['91.96%', '89.92%', '60.41%', '39.63%', '29.09%', '30.24%']\n",
            "fscore:    ['82.58%', '87.84%', '64.62%', '51.04%', '40.85%', '42.93%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 74.4%\n",
            "total recall (weighted): 68.16%\n",
            "total fscore (weighted): 69.13%\n",
            "CPU times: user 1min 5s, sys: 46.9 ms, total: 1min 5s\n",
            "Wall time: 1min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSF-KJZJRBI_",
        "colab_type": "code",
        "outputId": "65cb1bfb-9ef7-4a70-97e0-846c3b612ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('model 0______________________________________________________')\n",
        "test_model[0].show_most_informative_features()\n",
        "print('model 1______________________________________________________')\n",
        "test_model[1].show_most_informative_features()\n",
        "print('model 2______________________________________________________')\n",
        "test_model[2].show_most_informative_features()\n",
        "print('model 3______________________________________________________')\n",
        "test_model[3].show_most_informative_features()\n",
        "print('model 4______________________________________________________')\n",
        "test_model[4].show_most_informative_features()\n",
        "print('model 5______________________________________________________')\n",
        "test_model[5].show_most_informative_features()\n",
        "print('model 6______________________________________________________')\n",
        "test_model[6].show_most_informative_features()\n",
        "print('model 7______________________________________________________')\n",
        "test_model[7].show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model 0______________________________________________________\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'B-LOC'\n",
            "    -inf label is 'I-LOC'\n",
            "  -4.473 is_title==True and label is 'O'\n",
            "  -3.940 is_name==True and label is 'O'\n",
            "  -3.250 is_lower==True and label is 'I-PER'\n",
            "   2.859 w+1=='quê' and label is 'I-PER'\n",
            "  -2.139 w-1=='Tuấn' and label is 'I-PER'\n",
            "  -1.833 w-1=='Chương' and label is 'I-PER'\n",
            "model 1______________________________________________________\n",
            "    -inf label is 'B-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   6.363 w-2=='Lý' and label is 'B-LOC'\n",
            "  -6.073 is_title==True and label is 'O'\n",
            "   5.003 w+2==':' and label is 'B-LOC'\n",
            "  -4.113 is_name==True and label is 'O'\n",
            "  -3.277 w+1=='”' and label is 'O'\n",
            "   3.068 w0+w+1=='Hồng ,' and label is 'O'\n",
            "model 2______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "  -4.443 is_name==True and label is 'O'\n",
            "   4.235 num_syllabus==3 and label is 'B-LOC'\n",
            "   3.784 w-2=='thuộc' and label is 'I-LOC'\n",
            "   3.715 has_hyphen==True and label is 'B-ORG'\n",
            "  -3.464 w-1=='Tuổi_Trẻ' and label is 'I-ORG'\n",
            "   3.375 w+1=='và' and label is 'I-LOC'\n",
            "  -2.763 r+1=='org_adm_div' and label is 'O'\n",
            "  -2.633 is_title==True and label is 'O'\n",
            "  -2.591 s-2=='O' and label is 'B-ORG'\n",
            "model 3______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "   4.231 w-2=='và' and label is 'B-ORG'\n",
            "   3.806 w-1=='môi_trường' and label is 'B-PER'\n",
            "   3.639 w-2=='môi_trường' and label is 'B-PER'\n",
            "   3.436 w-1=='RIT' and label is 'B-PER'\n",
            "   3.330 w+2=='cho' and label is 'B-ORG'\n",
            "   3.325 w-1=='Kinh_tế' and label is 'B-PER'\n",
            "   3.288 w-2=='Bộ' and label is 'B-LOC'\n",
            "   3.271 w-1=='Hà_Nội' and label is 'B-PER'\n",
            "   3.128 w-2=='về' and label is 'B-ORG'\n",
            "model 4______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "  -5.356 is_name==True and label is 'O'\n",
            "   4.713 w+2=='đã' and label is 'B-PER'\n",
            "   4.659 w-1=='Thái_Lan' and label is 'B-PER'\n",
            "  -4.293 is_title==True and label is 'O'\n",
            "   4.128 w+2=='bị' and label is 'B-LOC'\n",
            "   4.119 w+2==')' and label is 'B-PER'\n",
            "   4.073 w-2=='người' and label is 'B-LOC'\n",
            "   4.006 r+2=='street_digit' and label is 'B-LOC'\n",
            "model 5______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "   4.143 w+1=='Văn' and label is 'B-PER'\n",
            "   4.110 w-1=='Thống_Nhất' and label is 'B-LOC'\n",
            "  -3.787 is_title==True and label is 'O'\n",
            "  -3.345 is_name==True and label is 'O'\n",
            "   3.306 w-2=='thị_trấn' and label is 'B-LOC'\n",
            "   3.021 w-1=='World' and label is 'I-LOC'\n",
            "   2.984 w-2=='quán' and label is 'B-LOC'\n",
            "model 6______________________________________________________\n",
            "    -inf s-1=='BOS' and label is 'O'\n",
            "    -inf w-1=='BOS' and label is 'O'\n",
            "    -inf r-1=='BOS' and label is 'O'\n",
            "    -inf r0+r-1=='NA BOS' and label is 'O'\n",
            "    -inf s-1=='BOS' and label is 'B-ORG'\n",
            "    -inf w-1=='BOS' and label is 'B-ORG'\n",
            "    -inf r-1=='BOS' and label is 'B-ORG'\n",
            "    -inf r0+r-1=='NA BOS' and label is 'B-ORG'\n",
            "    -inf s-1=='BOS' and label is 'B-PER'\n",
            "    -inf w-1=='BOS' and label is 'B-PER'\n",
            "model 7______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   5.392 w+2=='thế_giới' and label is 'B-ORG'\n",
            "   5.338 w+1=='Sài_Gòn' and label is 'B-ORG'\n",
            "   5.083 w+2=='đầy' and label is 'B-LOC'\n",
            "   5.042 w+2=='?' and label is 'B-ORG'\n",
            "   4.528 w+2=='xem' and label is 'B-ORG'\n",
            "   4.453 w+2=='một_số' and label is 'B-LOC'\n",
            "   4.429 w+1=='bắt_đầu' and label is 'B-ORG'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}