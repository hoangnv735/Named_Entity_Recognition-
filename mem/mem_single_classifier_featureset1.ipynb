{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mem-single-classifier-featureset1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ren176NzPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "334a5b45-d10f-4b58-8f09-b1b7ece59ca7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv0m83olOA9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pickle\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.classify.maxent import MaxentClassifier, BinaryMaxentFeatureEncoding\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSqfW0gJOCHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "efcdc2d9-0327-4429-bdc7-4991b1f189b2"
      },
      "source": [
        "# Global variables\n",
        "rawdata_path = \"/content/gdrive/My Drive/ml/data/rawdata/\"\n",
        "data_path = \"/content/gdrive/My Drive/ml/data/data/\"\n",
        "model_path = \"/content/gdrive/My Drive/ml/model/\"\n",
        "labels = ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'O']\n",
        "labels_dict = {labels[i]: i for i in range(len(labels))}\n",
        "eval_labels = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
        "print(labels_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAiI9t6MOJBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_xml_tags(filename):\n",
        "  ''' \n",
        "  Remove xml tag in file in data folder(raw data)\n",
        "  Args:\n",
        "    filename: The name of the data file in dataVLSP folder\n",
        "  Return:\n",
        "    File of the same name has removed xml tags in data folder\n",
        "  Example:\n",
        "    <editor>Vietlex team, 8-2016</editor>\n",
        "    -DOCSTART-\n",
        "    <s>\t\t\t\t\n",
        "    Đó\tP\tB-NP\tO\tO\n",
        "    là\tV\tB-VP\tO\tO\n",
        "    con\tNc\tB-NP\tO\tO\n",
        "  :converted into:\n",
        "    Đó\tP\tB-NP\tO\tO\n",
        "    là\tV\tB-VP\tO\tO\n",
        "    con\tNc\tB-NP\tO\tO\n",
        "\n",
        "    saved in dataVLSP folder(processed data)\n",
        "  '''\n",
        "  f1 = open(rawdata_path + filename, 'r',encoding='utf-8')\n",
        "  f2 = open(data_path + filename, 'w+',encoding='utf-8')\n",
        "  for line in f1:\n",
        "    line.strip()\n",
        "    if(('<title>' in line) or line.startswith('<e') or line.startswith('-D') or line.startswith('<s>')):\n",
        "      pass\n",
        "    elif(line.startswith('</')):\n",
        "      f2.write(line.replace(line,'\\n'))\n",
        "    else:\n",
        "      f2.write(line)\n",
        "  f1.close()\n",
        "  f2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hQPQW8OVRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(path):\n",
        "  ''' \n",
        "  Remove xml tags of all files in the dataVLSP folder\n",
        "  Processed data saved in data\n",
        "  '''\n",
        "  list_files = os.listdir(path)\n",
        "  for file in list_files:\n",
        "    remove_xml_tags(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIHOHV-MOZSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "    ''' Create training data and testing data\n",
        "        Format of data: CoNLL\n",
        "\n",
        "        Args:\n",
        "        path: path of data folder\n",
        "        scale: test size\n",
        "        index_attri: Represents the number of attributes and the associated attribute type\n",
        "            index_attri == 1 : The number of attributes = 1 - only ner label. ex: [('Huế', 'B_LOC'), ('là', 'O'), ('thành_phố', 'O'), ('đẹp', 'O')]\n",
        "            index_attri == 2.1 : The number of attributes = 2(pos-tagging label, ner label). ex: [('Đó', 'P', 'O'), ('là', 'V',  'O'), ('con', 'Nc', 'O'), ('đường', 'N', , 'O')]\n",
        "            index_attri = 2.2 : The number of attributes = 2(chunking label, ner label). ex: [('Đó', 'B-NP', 'O'), ('là', 'B-VP', 'O'), ('con', 'B-NP', 'O'), ('đường', 'B-NP', 'O')]\n",
        "            index_attri = 3 : The number of attributes = 3(pos-tagging label,chunking, ner label). ex: [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')]\n",
        "            if index_attri not in {1,2.1,2,2,3} index_attri = 2.1\n",
        "        Return:\n",
        "        train_sents, test_sents\n",
        "        \n",
        "        Example of format data:\n",
        "        [[('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "        [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "    '''    \n",
        "    list_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    ''' Convert data format to CoNll '''\n",
        "    #training data\n",
        "    c = 0;\n",
        "    pos_tag = []\n",
        "    chunk_tag = []\n",
        "    ne_tag = []\n",
        "    for file in list_files:\n",
        "        with codecs.open(path + file,'r',encoding='utf8') as f:\n",
        "            sentence = []\n",
        "            remove = False\n",
        "            for line in f:\n",
        "                line = line.split()\n",
        "                if len(line) > 3:\n",
        "                    #label_set.append(line[3])\n",
        "                    if line[3] not in labels:\n",
        "                        remove = True\n",
        "                    else:\n",
        "                        pos_tag.append(line[1])\n",
        "                        chunk_tag.append(line[2])\n",
        "                    sentence.append((line[0],line[1],line[2],line[3]))\n",
        "                else:\n",
        "                    if len(sentence) > 0:\n",
        "                        if remove == False:                            \n",
        "                            all_data.append(sentence)\n",
        "                        else:\n",
        "                            remove = False\n",
        "                        sentence = []\n",
        "            f.close()\n",
        "\n",
        "    pos_tag = set(pos_tag)\n",
        "    chunk_tag = set(chunk_tag)\n",
        "    return  all_data, pos_tag, chunk_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKqNUvkrYh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_feature(word):\n",
        "    is_lower            = 'is_lower'\n",
        "    is_capital          = 'is_capital' \n",
        "    is_title            = 'is_title' \n",
        "    is_mix              = 'is_mix' \n",
        "    is_capital_period   = 'is_capital_period' \n",
        "    is_digit            = 'is_digit' \n",
        "    end_digit           = 'end_digit' \n",
        "    has_hyphen          = 'has_hyphen' \n",
        "    is_code             = 'is_code' \n",
        "    num_syllabus        = 'num_syllabus'\n",
        "    is_name             = 'is_name' \n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break;\n",
        "\n",
        "    ft = {\n",
        "        'bias'                : 1,\n",
        "        is_lower            : word.islower(),\n",
        "        is_capital          : word.isupper(),\n",
        "        is_title            : word.istitle(),\n",
        "        is_mix              : not(word.islower() and word.isupper()),\n",
        "        is_capital_period   : (('.' in word) and word[0].isupper()),\n",
        "        is_digit            : word.isdigit(),\n",
        "        end_digit           : word[-1].isdigit(),\n",
        "        has_hyphen          : ('-' in word),\n",
        "        is_code             : check_code,\n",
        "        num_syllabus        : (word.count('_') + 1),\n",
        "        is_name             : word[0].isupper()\n",
        "    }   \n",
        "    return ft\n",
        "\n",
        "def word_feature(sent, i, pre_state, pre_pre_state):\n",
        "    word = sent[i][0]\n",
        "    ft = dict()\n",
        "    ### basic feature \n",
        "    # current word\n",
        "    ft['w0'] = word\n",
        "    # previous entity tag\n",
        "    ft['s-1'] = pre_state\n",
        "    ### basic shape feature\n",
        "    ft.update(shape_feature(word))\n",
        "    #### basic joint feature\n",
        "    if i > 0:\n",
        "        ft['w-1'] = sent[i-1][0]\n",
        "    else:\n",
        "        ft['w-1'] = 'BOS'\n",
        "    if i > 1:\n",
        "        ft['w-2'] = sent[i-2][0]\n",
        "    else:\n",
        "        ft['w-2'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['w+1'] = sent[i+1][0]\n",
        "    else:\n",
        "        ft['w+1'] = 'EOS'\n",
        "    if i < len(sent)-2:\n",
        "        ft['w+2'] = sent[i+2][0]\n",
        "    else:\n",
        "        ft['w+2'] = 'EOS'\n",
        "    return ft\n",
        "\n",
        "def sent_feature_train(sent):\n",
        "    sent_ft_train = list()\n",
        "    for i in range(len(sent)):\n",
        "        if i < 1:\n",
        "            sent_ft_train.append((word_feature(sent, i, 'BOS', 'BOS'),\n",
        "                                  labels_dict[sent[i][3]]))\n",
        "        elif i < 2:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], 'BOS'),\n",
        "                                  labels_dict[sent[i][3]]))\n",
        "        else:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], sent[i-2][3]),\n",
        "                                  labels_dict[sent[i][3]]))    \n",
        "    return sent_ft_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKMAqgykrg84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_feature_test(sent, pre_state, pre_pre_state):\n",
        "    sent_ft_test = list()\n",
        "    for i in range(len(sent)):\n",
        "        sent_ft_test.append(word_feature(sent, i, pre_state, pre_pre_state))    \n",
        "    return sent_ft_test   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqd8SZjDrle6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_decoder(model, sent):\n",
        "    alpha = [([0] * len(labels)) for i in range(len(sent))]\n",
        "    trace = np.full(shape=(len(sent), len(labels)), fill_value=-1)\n",
        "\n",
        "    # start probability\n",
        "    pdist = model.prob_classify(word_feature(sent, 0, 'BOS', 'BOS'))    \n",
        "    alpha[0] = [pdist.prob(l) for l in labels]\n",
        "    \n",
        "    for i in range(1, len(sent)):\n",
        "        alpha[i] = [0] * len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            pre_state = labels[j];\n",
        "            pre_pre_state = 'BOS'\n",
        "            if i > 1:\n",
        "                pre_pre_state = labels[trace[i-1][j]];\n",
        "            feature = word_feature(sent, i, pre_state, pre_pre_state)\n",
        "            pdist = model.prob_classify(feature)                \n",
        "            posterior = [pdist.prob(l) for l in labels]\n",
        "            for k in range(len(labels)):\n",
        "                if alpha[i][k] < (posterior[k] * alpha[i-1][j]):\n",
        "                    alpha[i][k] = posterior[k] * alpha[i-1][j]\n",
        "                    trace[i][k] = j\n",
        "    m = alpha[-1][0]\n",
        "    idx = 0\n",
        "    for i in range(1, len(alpha[-1])):\n",
        "        if (alpha[-1][i] > m):\n",
        "            m = alpha[-1][i]\n",
        "            idx = i;\n",
        "    predict = list()\n",
        "    for i in range(len(sent)-1, -1, -1):\n",
        "        predict.append(labels[idx])\n",
        "        idx = trace[i][idx]\n",
        "    # print(alpha)\n",
        "    return reversed(predict)\n",
        "\n",
        "def predict_sent(model, sent):\n",
        "    y_test_sent = [sent[i][3] for i in range(len(sent))]   \n",
        "    y_pred_sent = viterbi_decoder(model, sent)\n",
        "    return y_test_sent, y_pred_sent\n",
        "\n",
        "def predict(model, sents):\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for sent in sents:\n",
        "        test, pred = predict_sent(model, sent)\n",
        "        y_test.extend(test)\n",
        "        y_pred.extend(pred)\n",
        "    return y_test, y_pred   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9Y0-wLsJ66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "158923fd-8a6d-4a91-fa83-178df98f207d"
      },
      "source": [
        "all_data, pos_tag, chunk_tag = prepare_data(data_path)\n",
        "train_sents, test_sents = train_test_split(all_data, test_size = 0.15, random_state=42)\n",
        "print(\"train_sents\", len(train_sents))\n",
        "print(\"test_sents\", len(test_sents))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents 14087\n",
            "test_sents 2486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6XXtDhUsLia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2f95ee3d-7d4f-4607-f378-76bf14be3970"
      },
      "source": [
        "train_data = []\n",
        "for sent in train_sents:\n",
        "    for feature, label in sent_feature_train(sent):\n",
        "        train_data.append((feature, labels[label]))     \n",
        "\n",
        "print('train_data length', len(train_data))\n",
        "print(train_data[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data length 305800\n",
            "({'w0': 'Ngoài', 's-1': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'BOS', 'w-2': 'BOS', 'w+1': 'một_số', 'w+2': 'nhỏ'}, 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80z8Eb1usEuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "48bdb9e0-690d-4fdd-e1be-0c8890a36162"
      },
      "source": [
        "%%time \n",
        "max_iter = 10\n",
        "encoding = BinaryMaxentFeatureEncoding.train(train_data, count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "model = MaxentClassifier.train(train_data, algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-single-classifier-featureset1-binaryfeature-maxiter10.model\", \"wb\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94591        0.937\n",
            "             2          -0.10011        0.937\n",
            "             3          -0.09519        0.937\n",
            "             4          -0.08642        0.941\n",
            "             5          -0.07782        0.950\n",
            "             6          -0.07047        0.960\n",
            "             7          -0.06436        0.968\n",
            "             8          -0.05929        0.974\n",
            "             9          -0.05506        0.978\n",
            "         Final          -0.05150        0.981\n",
            "CPU times: user 34min 27s, sys: 3.47 s, total: 34min 30s\n",
            "Wall time: 34min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDN1QgwIsPY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1b279c24-7b00-45e0-ab90-c46aab67df24"
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-single-classifier-featureset1-binaryfeature-maxiter10.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['91.03%', '93.65%', '88.12%', '87.5%', '88.57%', '90.28%']\n",
            "recall:    ['74.93%', '78.52%', '30.72%', '9.68%', '18.79%', '22.34%']\n",
            "fscore:    ['82.2%', '85.42%', '45.56%', '17.43%', '31.0%', '35.81%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 90.04%\n",
            "total recall (weighted): 48.17%\n",
            "total fscore (weighted): 58.2%\n",
            "CPU times: user 57.8 s, sys: 17 ms, total: 57.8 s\n",
            "Wall time: 57.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c51b40fe-3130-46d6-a70d-ab21b0276882",
        "id": "1WCgqFMvLSiW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "test_model.show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  -4.536 s-1=='O' and label is 'I-PER'\n",
            "  -4.420 s-1=='O' and label is 'I-ORG'\n",
            "  -3.836 is_name==False and label is 'B-PER'\n",
            "  -3.750 s-1=='O' and label is 'I-LOC'\n",
            "  -3.600 is_lower==True and label is 'B-PER'\n",
            "  -3.546 s-1=='B-PER' and label is 'B-PER'\n",
            "  -3.102 w0=='VN' and label is 'O'\n",
            "  -2.956 s-1=='I-PER' and label is 'B-LOC'\n",
            "   2.867 w0=='sư' and label is 'B-ORG'\n",
            "  -2.755 w+1=='EOS' and label is 'B-LOC'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}