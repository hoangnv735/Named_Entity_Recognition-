{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mem-single-classifier-featureset3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PaJ9kb9mZpB",
        "colab_type": "code",
        "outputId": "b3acde8f-8285-4d8f-ba84-d64b750ab2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ELpRuLimgo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pickle\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.classify.maxent import MaxentClassifier, TypedMaxentFeatureEncoding, BinaryMaxentFeatureEncoding\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qps0EYp9mio3",
        "colab_type": "code",
        "outputId": "92af09ea-70c6-447f-cbe3-94502b26f851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Global variables\n",
        "rawdata_path = \"/content/gdrive/My Drive/ml/data/rawdata/\"\n",
        "data_path = \"/content/gdrive/My Drive/ml/data/data/\"\n",
        "model_path = \"/content/gdrive/My Drive/ml/model/\"\n",
        "labels = ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'O']\n",
        "labels_dict = {labels[i]: i for i in range(len(labels))}\n",
        "eval_labels = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
        "print(labels_dict)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjJ3GMSGmlcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_xml_tags(filename):\n",
        "  ''' \n",
        "  Remove xml tag in file in data folder(raw data)\n",
        "  Args:\n",
        "    filename: The name of the data file in dataVLSP folder\n",
        "  Return:\n",
        "    File of the same name has removed xml tags in data folder\n",
        "  Example:\n",
        "    <editor>Vietlex team, 8-2016</editor>\n",
        "    -DOCSTART-\n",
        "    <s>\t\t\t\t\n",
        "    Đó\tP\tB-NP\tO\tO\n",
        "    là\tV\tB-VP\tO\tO\n",
        "    con\tNc\tB-NP\tO\tO\n",
        "  :converted into:\n",
        "    Đó\tP\tB-NP\tO\tO\n",
        "    là\tV\tB-VP\tO\tO\n",
        "    con\tNc\tB-NP\tO\tO\n",
        "\n",
        "    saved in dataVLSP folder(processed data)\n",
        "  '''\n",
        "  f1 = open(rawdata_path + filename, 'r',encoding='utf-8')\n",
        "  f2 = open(data_path + filename, 'w+',encoding='utf-8')\n",
        "  for line in f1:\n",
        "    line.strip()\n",
        "    if(('<title>' in line) or line.startswith('<e') or line.startswith('-D') or line.startswith('<s>')):\n",
        "      pass\n",
        "    elif(line.startswith('</')):\n",
        "      f2.write(line.replace(line,'\\n'))\n",
        "    else:\n",
        "      f2.write(line)\n",
        "  f1.close()\n",
        "  f2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTrlk6X4mnf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(path):\n",
        "  ''' \n",
        "  Remove xml tags of all files in the dataVLSP folder\n",
        "  Processed data saved in data\n",
        "  '''\n",
        "  list_files = os.listdir(path)\n",
        "  for file in list_files:\n",
        "    remove_xml_tags(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZPIaCVen4_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "    ''' Create training data and testing data\n",
        "        Format of data: CoNLL\n",
        "\n",
        "        Args:\n",
        "        path: path of data folder\n",
        "        scale: test size\n",
        "        index_attri: Represents the number of attributes and the associated attribute type\n",
        "            index_attri == 1 : The number of attributes = 1 - only ner label. ex: [('Huế', 'B_LOC'), ('là', 'O'), ('thành_phố', 'O'), ('đẹp', 'O')]\n",
        "            index_attri == 2.1 : The number of attributes = 2(pos-tagging label, ner label). ex: [('Đó', 'P', 'O'), ('là', 'V',  'O'), ('con', 'Nc', 'O'), ('đường', 'N', , 'O')]\n",
        "            index_attri = 2.2 : The number of attributes = 2(chunking label, ner label). ex: [('Đó', 'B-NP', 'O'), ('là', 'B-VP', 'O'), ('con', 'B-NP', 'O'), ('đường', 'B-NP', 'O')]\n",
        "            index_attri = 3 : The number of attributes = 3(pos-tagging label,chunking, ner label). ex: [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')]\n",
        "            if index_attri not in {1,2.1,2,2,3} index_attri = 2.1\n",
        "        Return:\n",
        "        train_sents, test_sents\n",
        "        \n",
        "        Example of format data:\n",
        "        [[('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "        [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "    '''    \n",
        "    list_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    ''' Convert data format to CoNll '''\n",
        "    #training data\n",
        "    c = 0;\n",
        "    pos_tag = []\n",
        "    chunk_tag = []\n",
        "    ne_tag = []\n",
        "    for file in list_files:\n",
        "        with codecs.open(path + file,'r',encoding='utf8') as f:\n",
        "            sentence = []\n",
        "            remove = False\n",
        "            for line in f:\n",
        "                line = line.split()\n",
        "                if len(line) > 3:\n",
        "                    #label_set.append(line[3])\n",
        "                    if line[3] not in labels:\n",
        "                        remove = True\n",
        "                    else:\n",
        "                        pos_tag.append(line[1])\n",
        "                        chunk_tag.append(line[2])\n",
        "                    sentence.append((line[0],line[1],line[2],line[3]))\n",
        "                else:\n",
        "                    if len(sentence) > 0:\n",
        "                        if remove == False:                            \n",
        "                            all_data.append(sentence)\n",
        "                        else:\n",
        "                            remove = False\n",
        "                        sentence = []\n",
        "            f.close()\n",
        "\n",
        "    pos_tag = set(pos_tag)\n",
        "    chunk_tag = set(chunk_tag)\n",
        "    return  all_data, pos_tag, chunk_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwuSfyrQoF5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_feature(word):\n",
        "    is_lower            = 'is_lower'\n",
        "    is_capital          = 'is_capital' \n",
        "    is_title            = 'is_title' \n",
        "    is_mix              = 'is_mix' \n",
        "    is_capital_period   = 'is_capital_period' \n",
        "    is_digit            = 'is_digit' \n",
        "    end_digit           = 'end_digit' \n",
        "    has_hyphen          = 'has_hyphen' \n",
        "    is_code             = 'is_code' \n",
        "    num_syllabus        = 'num_syllabus'\n",
        "    is_name             = 'is_name' \n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break;\n",
        "\n",
        "    ft = {\n",
        "        'bias'                : 1,\n",
        "        is_lower            : word.islower(),\n",
        "        is_capital          : word.isupper(),\n",
        "        is_title            : word.istitle(),\n",
        "        is_mix              : not(word.islower() and word.isupper()),\n",
        "        is_capital_period   : (('.' in word) and word[0].isupper()),\n",
        "        is_digit            : word.isdigit(),\n",
        "        end_digit           : word[-1].isdigit(),\n",
        "        has_hyphen          : ('-' in word),\n",
        "        is_code             : check_code,\n",
        "        num_syllabus        : (word.count('_') + 1),\n",
        "        is_name             : word[0].isupper()\n",
        "    }   \n",
        "    return ft\n",
        "\n",
        "def word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft):\n",
        "    word = sent[i][0]\n",
        "    ft = dict()\n",
        "    ### basic feature \n",
        "    # current word\n",
        "    ft['w0'] = word\n",
        "    # previous entity tag\n",
        "    ft['s-1'] = pre_state\n",
        "    ft['s-2'] = pre_pre_state\n",
        "    ### basic shape feature\n",
        "    ft.update(shape_feature(word))\n",
        "    ### basic joint feature\n",
        "    if i > 0:\n",
        "        ft['w-1'] = sent[i-1][0]\n",
        "    else:\n",
        "        ft['w-1'] = 'BOS'\n",
        "    \n",
        "    if i > 1:\n",
        "        ft['w-2'] = sent[i-2][0]\n",
        "    else:\n",
        "        ft['w-2'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['w+1'] = sent[i+1][0]\n",
        "    else:\n",
        "        ft['w+1'] = 'EOS'    \n",
        "    if i < len(sent)-2:\n",
        "        ft['w+2'] = sent[i+2][0]\n",
        "    else:\n",
        "        ft['w+2'] = 'EOS'\n",
        "    ### regular expression type\n",
        "    ft['r0'] = sent_re_ft[i]\n",
        "    if i > 0:\n",
        "        ft['r-1'] = sent_re_ft[i-1]\n",
        "    else:\n",
        "        ft['r-1'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['r+1'] = sent_re_ft[i+1]\n",
        "    else:        \n",
        "        ft['r+1'] = 'EOS'\n",
        "    if i > 1:\n",
        "        ft['r-2'] = sent_re_ft[i-2]\n",
        "    else:\n",
        "        ft['r-2'] = 'BOS'\n",
        "    if i < len(sent)-2:\n",
        "        ft['r+2'] = sent_re_ft[i+2]\n",
        "    else:\n",
        "        ft['r+2'] = 'EOS'\n",
        "    ### extra joint feature\n",
        "    ft['w0+w-1'] = ft['w0'] + ' ' + ft['w-1']\n",
        "    ft['w0+w+1'] = ft['w0'] + ' ' + ft['w+1']\n",
        "    ft['w0+s-1'] = ft['w0'] + ' ' + ft['s-1']\n",
        "    ft['r0+r-1'] = ft['r0'] + ' ' + ft['r-1']\n",
        "    ft['r0+r+1'] = ft['r0'] + ' ' + ft['r+1']\n",
        "    ft['w0+r0']  = ft['w0'] + ' ' + ft['r0']\n",
        "    ft['w0+r-1'] = ft['w0'] + ' ' + ft['r-1']\n",
        "    ft['w0+r+1'] = ft['w0'] + ' ' + ft['r+1']\n",
        "    return ft\n",
        "re_adm_div      = ['ấp', 'buôn', 'bản', 'huyện', 'làng', 'miền', 'nước', \n",
        "                   'phường', 'quận', 'tỉnh', 'thành_phố', 'thị_trấn', 'thị_xã', \n",
        "                   'thôn', 'TT', 'TP', 'TX', 'TT.', 'TP.', 'TX.', 'xứ', 'xã', \n",
        "                   'xóm']\n",
        "re_org          = ['báo', 'bệnh_viện', 'bệnh_xá', 'công_ty', 'công_ti', 'đài', 'đảng', 'đoàn', 'hội', 'hợp_tác_xã', 'khách_sạn', 'nhà_máy', 'nhà_xuất_bản', 'ngân_hàng', 'quỹ', 'tạp_chí', 'tập đoàn', 'thông_tấn_xã', 'tờ', 'trạm_xá', 'xí_nghiệp','ủy_ban']\n",
        "re_school       = ['mẫu_giáo', 'tiểu_học', 'trung_học', 'trung_học_cơ_sở', \n",
        "                   'trung_học_phổ_thông', 'cao_đẳng', 'trung_cấp', \n",
        "                   'trung_cấp_nghề', 'đại_học']\n",
        "re_street       = ['đại_lộ', 'đường', 'hẻm', 'ngách', 'ngõ', 'nhà', 'phố', 'quốc_lộ']\n",
        "re_place        = ['ao', 'am', 'bến', 'bến_cảng', 'bến_phà','biển', 'cảng', \n",
        "                   'cầu', 'công_viên', 'chợ', 'chùa', 'dãy', 'đảo', 'đầm', 'đèo', \n",
        "                   'đền', 'đình', 'đồi', 'động', 'đồng_bằng', 'gềnh', 'gò', 'khu', 'hòn', 'hồ', \n",
        "                   'lăng', 'miếu', 'miền', 'nhà_ga', 'núi', 'phà', 'quần_đảo', \n",
        "                   'sân_bay', 'sông', 'suối', 'vùng']\n",
        "re_office       = ['ban', 'bộ', 'chi_cục', 'cục', 'hạt', 'sở']\n",
        "re_army         = ['binh_đoàn', 'đại_đội', 'đặc_khu', 'đơn_vị', 'lữ_đoàn', 'quân_đoàn', 'quân_đội', 'quân_khu','sư_đoàn', 'tiểu_đội', 'tiểu_đoàn', 'trung_đội']\n",
        "\n",
        "def re_word(word):\n",
        "    \"\"\"\n",
        "        Return a dict of (regexp Name, regexp Value) of a word\n",
        "        :type word: string\n",
        "        :param word: a word in sentence\n",
        "    \"\"\"\n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break\n",
        "\n",
        "    re_dict = dict()\n",
        "    re_dict['org'] = word.lower() in re_org\n",
        "    re_dict['name'] = word[0].isupper()\n",
        "    re_dict['capital'] = word.isupper()\n",
        "    re_dict['adm_div'] = word.lower() in re_adm_div\n",
        "    re_dict['is_school'] = word.lower() == 'trường'\n",
        "    re_dict['school'] = word.lower() in re_school\n",
        "    re_dict['street'] = word.lower() in re_street\n",
        "    re_dict['digit'] = word.isdigit()\n",
        "    re_dict['code'] = check_code\n",
        "    re_dict['place'] =  word in re_place\n",
        "    re_dict['office'] = word in re_office\n",
        "    re_dict['army'] = word in re_army\n",
        "    return re_dict \n",
        "\n",
        "re_type_name = [ \n",
        "    ('ofice_name_admdiv_name', ['office', 'name', 'adm_div', 'name']),\n",
        "    ('school_type_name_name'     , ['is_school', 'school', 'name', 'name']),\n",
        "    ('school_capital_name_name'  , ['is_school', 'capital', 'name', 'name']),\n",
        "    ('org_cap_name_name'         , ['org', 'capital', 'name', 'name']),\n",
        "    ('org_adm_div'          , ['capital', 'adm_div', 'name']),\n",
        "    ('school_type_name'     , ['is_school', 'school', 'name']),\n",
        "    ('school_capital_name'  , ['is_school', 'capital', 'name']),\n",
        "    ('org_cap_name'         , ['org', 'capital', 'name']),\n",
        "    ('place_name_name'           , ['place', 'name', 'name']),\n",
        "    ('place_name'           , ['place', 'name']),\n",
        "    ('org_name'                  , ['org', 'name', 'name']),\n",
        "    ('school_name_name'          , ['school', 'name', 'name']),\n",
        "    ('office_name_name'               , ['office', 'name', 'name']),\n",
        "    ('street_name_name'          , ['street', 'name', 'name']),\n",
        "    ('org'                  , ['org', 'name']),\n",
        "    ('school_name'          , ['school', 'name']),\n",
        "    ('adm_div'              , ['adm_div', 'name']),\n",
        "    ('office_name'               , ['office', 'name']),\n",
        "    ('street_name'          , ['street', 'name']),\n",
        "    ('street_digit'         , ['street', 'digit']),\n",
        "    ('street_code'          , ['street', 'code']),\n",
        "    ('army_name'            , ['army', 'code']),\n",
        "    ('army_name'            , ['army', 'digit']),\n",
        "    ('army_name'            , ['army', 'name'])\n",
        "]\n",
        "\n",
        "def sent_re_feature(sent):\n",
        "    l = len(sent)\n",
        "    sent_re_ft = ['NA'] * l\n",
        "    re_dict_word = [re_word(word[0]) for word in sent]\n",
        "    for type_name in re_type_name:\n",
        "        tl = len(type_name[1])\n",
        "        for i in range(l):\n",
        "            if (i + tl <= l):\n",
        "                if (set(['NA']) == set([sent_re_ft[i+j] for j in range(tl)])) and (set([True]) == set([re_dict_word[i+ll][type_name[1][ll]] for ll in range(tl)])):\n",
        "                    for k in range(tl):\n",
        "                        sent_re_ft[i+k] = type_name[0]\n",
        "    return sent_re_ft\n",
        "\n",
        "def sent_feature_train(sent):\n",
        "    sent_ft_train = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        if i < 1:\n",
        "            sent_ft_train.append((word_feature(sent, i, 'BOS', 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]]))\n",
        "        elif i < 2:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]]))\n",
        "        else:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], sent[i-2][3], sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]]))    \n",
        "    return sent_ft_train          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XJnunBsoQIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_feature_test(sent, pre_state, pre_pre_state):\n",
        "    sent_ft_test = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        sent_ft_test.append(word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft))    \n",
        "    return sent_ft_test   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8BkHsYboWES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_decoder(model, sent):\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    alpha = [([0] * len(labels)) for i in range(len(sent))]\n",
        "    trace = np.full(shape=(len(sent), len(labels)), fill_value=-1)\n",
        "\n",
        "    # start probability\n",
        "    pdist = model.prob_classify(word_feature(sent, 0, 'BOS', 'BOS', sent_re_ft))    \n",
        "    alpha[0] = [pdist.prob(l) for l in labels]\n",
        "    \n",
        "    for i in range(1, len(sent)):\n",
        "        alpha[i] = [0] * len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            pre_state = labels[j];\n",
        "            pre_pre_state = 'BOS'\n",
        "            if i > 1:\n",
        "                pre_pre_state = labels[trace[i-1][j]];\n",
        "            feature = word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft)\n",
        "            pdist = model.prob_classify(feature)                \n",
        "            posterior = [pdist.prob(l) for l in labels]\n",
        "            for k in range(len(labels)):\n",
        "                if alpha[i][k] < (posterior[k] * alpha[i-1][j]):\n",
        "                    alpha[i][k] = posterior[k] * alpha[i-1][j]\n",
        "                    trace[i][k] = j\n",
        "    m = alpha[-1][0]\n",
        "    idx = 0\n",
        "    for i in range(1, len(alpha[-1])):\n",
        "        if (alpha[-1][i] > m):\n",
        "            m = alpha[-1][i]\n",
        "            idx = i;\n",
        "    predict = list()\n",
        "    for i in range(len(sent)-1, -1, -1):\n",
        "        predict.append(labels[idx])\n",
        "        idx = trace[i][idx]\n",
        "    # print(alpha)\n",
        "    return reversed(predict)\n",
        "\n",
        "def predict_sent(model, sent):\n",
        "    y_test_sent = [sent[i][3] for i in range(len(sent))]   \n",
        "    y_pred_sent = viterbi_decoder(model, sent)\n",
        "    return y_test_sent, y_pred_sent\n",
        "\n",
        "def predict(model, sents):\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for sent in sents:\n",
        "        test, pred = predict_sent(model, sent)\n",
        "        y_test.extend(test)\n",
        "        y_pred.extend(pred)\n",
        "    return y_test, y_pred            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqIUg9aJocbp",
        "colab_type": "code",
        "outputId": "cc3b232e-ee7e-4214-c9c3-b55f7da9d2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_data, pos_tag, chunk_tag = prepare_data(data_path)\n",
        "train_sents, test_sents = train_test_split(all_data, test_size = 0.15, random_state=42)\n",
        "print(\"train_sents\", len(train_sents))\n",
        "print(\"test_sents\", len(test_sents))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents 14087\n",
            "test_sents 2486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrNuu7Y7ofvg",
        "colab_type": "code",
        "outputId": "75462806-dcdb-42b4-b527-d01562c1c591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "train_data = []\n",
        "for sent in train_sents:\n",
        "    for feature, label in sent_feature_train(sent):\n",
        "        train_data.append((feature, labels[label]))     \n",
        "\n",
        "print('train_data length', len(train_data))\n",
        "print(train_data[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data length 305800\n",
            "({'w0': 'Ngoài', 's-1': 'BOS', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'BOS', 'w-2': 'BOS', 'w+1': 'một_số', 'w+2': 'nhỏ', 'r0': 'NA', 'r-1': 'BOS', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA', 'w0+w-1': 'Ngoài BOS', 'w0+w+1': 'Ngoài một_số', 'w0+s-1': 'Ngoài BOS', 'r0+r-1': 'NA BOS', 'r0+r+1': 'NA NA', 'w0+r0': 'Ngoài NA', 'w0+r-1': 'Ngoài BOS', 'w0+r+1': 'Ngoài NA'}, 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_C3bqmy1lDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "3c62a87a-a5ea-4908-add2-ecc511d3b9c9"
      },
      "source": [
        "%%time \n",
        "max_iter = 10\n",
        "encoding = BinaryMaxentFeatureEncoding.train(train_data, count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "model = MaxentClassifier.train(train_data, algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-single-classifier-featureset3-binaryfeature-maxiter10.model\", \"wb\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94591        0.937\n",
            "             2          -0.10321        0.937\n",
            "             3          -0.09262        0.938\n",
            "             4          -0.07888        0.950\n",
            "             5          -0.06742        0.962\n",
            "             6          -0.05874        0.971\n",
            "             7          -0.05214        0.978\n",
            "             8          -0.04700        0.982\n",
            "             9          -0.04292        0.985\n",
            "         Final          -0.03959        0.987\n",
            "CPU times: user 54min 30s, sys: 4.21 s, total: 54min 34s\n",
            "Wall time: 54min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlKQncjI0dgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "25ea3fd2-2bef-4626-b054-f6fab4b81945"
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-single-classifier-featureset3-binaryfeature-maxiter10.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['93.35%', '97.28%', '88.54%', '91.12%', '83.95%', '87.3%']\n",
            "recall:    ['83.73%', '74.9%', '62.26%', '63.82%', '41.21%', '37.8%']\n",
            "fscore:    ['88.28%', '84.64%', '73.11%', '75.07%', '55.28%', '52.76%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 91.44%\n",
            "total recall (weighted): 68.07%\n",
            "total fscore (weighted): 77.32%\n",
            "CPU times: user 1min 22s, sys: 21 ms, total: 1min 22s\n",
            "Wall time: 1min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pybUpvAKKTe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8fec312a-8ab6-4da7-f14c-37c45a4d9213"
      },
      "source": [
        "test_model.show_most_informative_features()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  -3.242 s-1=='O' and label is 'I-PER'\n",
            "  -2.983 s-1=='O' and label is 'I-ORG'\n",
            "  -2.828 is_name==False and label is 'B-PER'\n",
            "  -2.812 is_lower==True and label is 'B-PER'\n",
            "  -2.540 s-1=='O' and label is 'I-LOC'\n",
            "  -2.378 s-1=='B-PER' and label is 'B-PER'\n",
            "  -2.026 is_title==False and label is 'B-PER'\n",
            "  -1.934 w-1=='Nguyễn' and label is 'O'\n",
            "  -1.929 s-1=='I-PER' and label is 'B-LOC'\n",
            "  -1.876 w-1=='TP.' and label is 'O'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VujM9NlhK8ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2dec9316-c661-4203-a27b-5ebaffaddf42"
      },
      "source": [
        "%%time \n",
        "max_iter = 50\n",
        "encoding = BinaryMaxentFeatureEncoding.train(train_data, count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "model = MaxentClassifier.train(train_data, algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-single-classifier-featureset3-binaryfeature-maxiter50.model\", \"wb\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  ==> Training (50 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94591        0.937\n",
            "             2          -0.10321        0.937\n",
            "             3          -0.09262        0.938\n",
            "             4          -0.07888        0.950\n",
            "             5          -0.06742        0.962\n",
            "             6          -0.05874        0.971\n",
            "             7          -0.05214        0.978\n",
            "             8          -0.04700        0.982\n",
            "             9          -0.04292        0.985\n",
            "            10          -0.03959        0.987\n",
            "            11          -0.03684        0.988\n",
            "            12          -0.03452        0.989\n",
            "            13          -0.03255        0.990\n",
            "            14          -0.03085        0.991\n",
            "            15          -0.02937        0.991\n",
            "            16          -0.02806        0.992\n",
            "            17          -0.02690        0.992\n",
            "            18          -0.02587        0.992\n",
            "            19          -0.02494        0.993\n",
            "            20          -0.02410        0.993\n",
            "            21          -0.02333        0.993\n",
            "            22          -0.02263        0.993\n",
            "            23          -0.02199        0.994\n",
            "            24          -0.02140        0.994\n",
            "            25          -0.02085        0.994\n",
            "            26          -0.02034        0.994\n",
            "            27          -0.01986        0.994\n",
            "            28          -0.01942        0.994\n",
            "            29          -0.01900        0.994\n",
            "            30          -0.01861        0.995\n",
            "            31          -0.01824        0.995\n",
            "            32          -0.01789        0.995\n",
            "            33          -0.01756        0.995\n",
            "            34          -0.01725        0.995\n",
            "            35          -0.01695        0.995\n",
            "            36          -0.01667        0.995\n",
            "            37          -0.01640        0.995\n",
            "            38          -0.01614        0.995\n",
            "            39          -0.01589        0.995\n",
            "            40          -0.01566        0.996\n",
            "            41          -0.01543        0.996\n",
            "            42          -0.01521        0.996\n",
            "            43          -0.01501        0.996\n",
            "            44          -0.01481        0.996\n",
            "            45          -0.01461        0.996\n",
            "            46          -0.01443        0.996\n",
            "            47          -0.01425        0.996\n",
            "            48          -0.01407        0.996\n",
            "            49          -0.01391        0.996\n",
            "         Final          -0.01374        0.996\n",
            "CPU times: user 4h 50min 8s, sys: 25.5 s, total: 4h 50min 34s\n",
            "Wall time: 4h 50min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_bOV-oIK_fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fc7355cc-19f7-4441-958b-acb044470214"
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-single-classifier-featureset3-binaryfeature-maxiter50.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['95.8%', '95.99%', '89.68%', '90.72%', '81.43%', '82.95%']\n",
            "recall:    ['90.73%', '91.06%', '79.98%', '72.12%', '69.09%', '61.86%']\n",
            "fscore:    ['93.2%', '93.46%', '84.55%', '80.36%', '74.75%', '70.87%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 91.75%\n",
            "total recall (weighted): 81.99%\n",
            "total fscore (weighted): 86.47%\n",
            "CPU times: user 1min 23s, sys: 12 ms, total: 1min 23s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8EJiepiLEPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "97dba16a-d504-461f-e1c1-1950a5fb8e34"
      },
      "source": [
        "test_model.show_most_informative_features()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  -8.562 s-1=='O' and label is 'I-PER'\n",
            "  -8.390 s-1=='O' and label is 'I-ORG'\n",
            "   7.713 w-1=='Ẩn' and label is 'B-PER'\n",
            "  -7.085 s-1=='O' and label is 'I-LOC'\n",
            "   7.033 w0+w-1=='ông những' and label is 'B-PER'\n",
            "  -6.989 s-1=='B-PER' and label is 'B-PER'\n",
            "   6.452 w-1=='Nhà' and label is 'I-ORG'\n",
            "   6.257 w-2=='Vietnam' and label is 'B-LOC'\n",
            "   6.144 w-1=='Hàn_Quốc' and label is 'B-ORG'\n",
            "   5.900 w-1=='mặt_trận' and label is 'B-ORG'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}