{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mem-multi-classifier-featureset2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gabUUCtVqD36",
        "colab_type": "code",
        "outputId": "c109fdec-0eae-44bf-ddf3-16df35e220e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ceiuGTl2b0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pickle\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.classify.maxent import MaxentClassifier, BinaryMaxentFeatureEncoding\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF24ddXqaxc",
        "colab_type": "code",
        "outputId": "156e2674-72f2-4a8b-94fe-7a70f97b8be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Global variables\n",
        "rawdata_path = \"/content/gdrive/My Drive/ml/data/rawdata/\"\n",
        "data_path = \"/content/gdrive/My Drive/ml/data/data/\"\n",
        "model_path = \"/content/gdrive/My Drive/ml/model/\"\n",
        "labels = ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'O']\n",
        "labels_dict = {labels[i]: i for i in range(len(labels))}\n",
        "eval_labels = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
        "print(labels_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOrPZ5D9qn3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "    ''' Create training data and testing data\n",
        "        Format of data: CoNLL\n",
        "\n",
        "        Args:\n",
        "        path: path of data folder\n",
        "        scale: test size\n",
        "        index_attri: Represents the number of attributes and the associated attribute type\n",
        "            index_attri == 1 : The number of attributes = 1 - only ner label. ex: [('Huế', 'B_LOC'), ('là', 'O'), ('thành_phố', 'O'), ('đẹp', 'O')]\n",
        "            index_attri == 2.1 : The number of attributes = 2(pos-tagging label, ner label). ex: [('Đó', 'P', 'O'), ('là', 'V',  'O'), ('con', 'Nc', 'O'), ('đường', 'N', , 'O')]\n",
        "            index_attri = 2.2 : The number of attributes = 2(chunking label, ner label). ex: [('Đó', 'B-NP', 'O'), ('là', 'B-VP', 'O'), ('con', 'B-NP', 'O'), ('đường', 'B-NP', 'O')]\n",
        "            index_attri = 3 : The number of attributes = 3(pos-tagging label,chunking, ner label). ex: [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')]\n",
        "            if index_attri not in {1,2.1,2,2,3} index_attri = 2.1\n",
        "        Return:\n",
        "        train_sents, test_sents\n",
        "        \n",
        "        Example of format data:\n",
        "        [[('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "        [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "    '''    \n",
        "    list_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    ''' Convert data format to CoNll '''\n",
        "    #training data\n",
        "    c = 0;\n",
        "    pos_tag = []\n",
        "    chunk_tag = []\n",
        "    ne_tag = []\n",
        "    for file in list_files:\n",
        "        with codecs.open(path + file,'r',encoding='utf8') as f:\n",
        "            sentence = []\n",
        "            remove = False\n",
        "            for line in f:\n",
        "                line = line.split()\n",
        "                if len(line) > 3:\n",
        "                    #label_set.append(line[3])\n",
        "                    if line[3] not in labels:\n",
        "                        remove = True\n",
        "                    else:\n",
        "                        pos_tag.append(line[1])\n",
        "                        chunk_tag.append(line[2])\n",
        "                    sentence.append((line[0],line[1],line[2],line[3]))\n",
        "                else:\n",
        "                    if len(sentence) > 0:\n",
        "                        if remove == False:                            \n",
        "                            all_data.append(sentence)\n",
        "                        else:\n",
        "                            remove = False\n",
        "                        sentence = []\n",
        "            f.close()\n",
        "\n",
        "    pos_tag = set(pos_tag)\n",
        "    chunk_tag = set(chunk_tag)\n",
        "    return  all_data, pos_tag, chunk_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ut2eUhP6TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_feature(word):\n",
        "    is_lower            = 'is_lower'\n",
        "    is_capital          = 'is_capital' \n",
        "    is_title            = 'is_title' \n",
        "    is_mix              = 'is_mix' \n",
        "    is_capital_period   = 'is_capital_period' \n",
        "    is_digit            = 'is_digit' \n",
        "    end_digit           = 'end_digit' \n",
        "    has_hyphen          = 'has_hyphen' \n",
        "    is_code             = 'is_code' \n",
        "    num_syllabus        = 'num_syllabus'\n",
        "    is_name             = 'is_name' \n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break;\n",
        "\n",
        "    ft = {\n",
        "        'bias'                : 1,\n",
        "        is_lower            : word.islower(),\n",
        "        is_capital          : word.isupper(),\n",
        "        is_title            : word.istitle(),\n",
        "        is_mix              : not(word.islower() and word.isupper()),\n",
        "        is_capital_period   : (('.' in word) and word[0].isupper()),\n",
        "        is_digit            : word.isdigit(),\n",
        "        end_digit           : word[-1].isdigit(),\n",
        "        has_hyphen          : ('-' in word),\n",
        "        is_code             : check_code,\n",
        "        num_syllabus        : (word.count('_') + 1),\n",
        "        is_name             : word[0].isupper()\n",
        "    }   \n",
        "    return ft\n",
        "\n",
        "def word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft):\n",
        "    word = sent[i][0]\n",
        "    ft = dict()\n",
        "    ### basic feature \n",
        "    # current word\n",
        "    ft['w0'] = word\n",
        "    # previous entity tag\n",
        "    ft['s-1'] = pre_state\n",
        "    ft['s-2'] = pre_pre_state\n",
        "    ### basic shape feature\n",
        "    ft.update(shape_feature(word))\n",
        "    ### basic joint feature\n",
        "    if i > 0:\n",
        "        ft['w-1'] = sent[i-1][0]\n",
        "    else:\n",
        "        ft['w-1'] = 'BOS'\n",
        "    if i > 1:\n",
        "        ft['w-2'] = sent[i-2][0]\n",
        "    else:\n",
        "        ft['w-2'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['w+1'] = sent[i+1][0]\n",
        "    else:\n",
        "        ft['w+1'] = 'EOS'\n",
        "    if i < len(sent)-2:\n",
        "        ft['w+2'] = sent[i+2][0]\n",
        "    else:\n",
        "        ft['w+2'] = 'EOS'\n",
        "    ### regular expression type\n",
        "    ft['r0'] = sent_re_ft[i]\n",
        "    if i > 0:\n",
        "        ft['r-1'] = sent_re_ft[i-1]\n",
        "    else:\n",
        "        ft['r-1'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['r+1'] = sent_re_ft[i+1]\n",
        "    else:        \n",
        "        ft['r+1'] = 'EOS'\n",
        "    if i > 1:\n",
        "        ft['r-2'] = sent_re_ft[i-2]\n",
        "    else:\n",
        "        ft['r-2'] = 'BOS'\n",
        "    if i < len(sent)-2:\n",
        "        ft['r+2'] = sent_re_ft[i+2]\n",
        "    else:\n",
        "        ft['r+2'] = 'EOS'\n",
        "    return ft\n",
        "re_adm_div      = ['ấp', 'buôn', 'bản', 'huyện', 'làng', 'miền', 'nước', \n",
        "                   'phường', 'quận', 'tỉnh', 'thành_phố', 'thị_trấn', 'thị_xã', \n",
        "                   'thôn', 'TT', 'TP', 'TX', 'TT.', 'TP.', 'TX.', 'xứ', 'xã', \n",
        "                   'xóm']\n",
        "re_org          = ['báo', 'bệnh_viện', 'bệnh_xá', 'công_ty', 'công_ti', 'đài', 'đảng', 'đoàn', 'hội', 'hợp_tác_xã', 'khách_sạn', 'nhà_máy', 'nhà_xuất_bản', 'ngân_hàng', 'quỹ', 'tạp_chí', 'tập đoàn', 'thông_tấn_xã', 'tờ', 'trạm_xá', 'xí_nghiệp','ủy_ban']\n",
        "re_school       = ['mẫu_giáo', 'tiểu_học', 'trung_học', 'trung_học_cơ_sở', \n",
        "                   'trung_học_phổ_thông', 'cao_đẳng', 'trung_cấp', \n",
        "                   'trung_cấp_nghề', 'đại_học']\n",
        "re_street       = ['đại_lộ', 'đường', 'hẻm', 'ngách', 'ngõ', 'nhà', 'phố', 'quốc_lộ']\n",
        "re_place        = ['ao', 'am', 'bến', 'bến_cảng', 'bến_phà','biển', 'cảng', \n",
        "                   'cầu', 'công_viên', 'chợ', 'chùa', 'dãy', 'đảo', 'đầm', 'đèo', \n",
        "                   'đền', 'đình', 'đồi', 'động', 'đồng_bằng', 'gềnh', 'gò', 'khu', 'hòn', 'hồ', \n",
        "                   'lăng', 'miếu', 'miền', 'nhà_ga', 'núi', 'phà', 'quần_đảo', \n",
        "                   'sân_bay', 'sông', 'suối', 'vùng']\n",
        "re_office       = ['ban', 'bộ', 'chi_cục', 'cục', 'hạt', 'sở']\n",
        "re_army         = ['binh_đoàn', 'đại_đội', 'đặc_khu', 'đơn_vị', 'lữ_đoàn', 'quân_đoàn', 'quân_đội', 'quân_khu','sư_đoàn', 'tiểu_đội', 'tiểu_đoàn', 'trung_đội']\n",
        "\n",
        "def re_word(word):\n",
        "    \"\"\"\n",
        "        Return a dict of (regexp Name, regexp Value) of a word\n",
        "        :type word: string\n",
        "        :param word: a word in sentence\n",
        "    \"\"\"\n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break\n",
        "\n",
        "    re_dict = dict()\n",
        "    re_dict['org'] = word.lower() in re_org\n",
        "    re_dict['name'] = word[0].isupper()\n",
        "    re_dict['capital'] = word.isupper()\n",
        "    re_dict['adm_div'] = word.lower() in re_adm_div\n",
        "    re_dict['is_school'] = word.lower() == 'trường'\n",
        "    re_dict['school'] = word.lower() in re_school\n",
        "    re_dict['street'] = word.lower() in re_street\n",
        "    re_dict['digit'] = word.isdigit()\n",
        "    re_dict['code'] = check_code\n",
        "    re_dict['place'] =  word in re_place\n",
        "    re_dict['office'] = word in re_office\n",
        "    re_dict['army'] = word in re_army\n",
        "    return re_dict \n",
        "\n",
        "re_type_name = [ \n",
        "    ('ofice_name_admdiv_name', ['office', 'name', 'adm_div', 'name']),\n",
        "    ('school_type_name_name'     , ['is_school', 'school', 'name', 'name']),\n",
        "    ('school_capital_name_name'  , ['is_school', 'capital', 'name', 'name']),\n",
        "    ('org_cap_name_name'         , ['org', 'capital', 'name', 'name']),\n",
        "    ('org_adm_div'          , ['capital', 'adm_div', 'name']),\n",
        "    ('school_type_name'     , ['is_school', 'school', 'name']),\n",
        "    ('school_capital_name'  , ['is_school', 'capital', 'name']),\n",
        "    ('org_cap_name'         , ['org', 'capital', 'name']),\n",
        "    ('place_name_name'           , ['place', 'name', 'name']),\n",
        "    ('place_name'           , ['place', 'name']),\n",
        "    ('org_name'                  , ['org', 'name', 'name']),\n",
        "    ('school_name_name'          , ['school', 'name', 'name']),\n",
        "    ('office_name_name'               , ['office', 'name', 'name']),\n",
        "    ('street_name_name'          , ['street', 'name', 'name']),\n",
        "    ('org'                  , ['org', 'name']),\n",
        "    ('school_name'          , ['school', 'name']),\n",
        "    ('adm_div'              , ['adm_div', 'name']),\n",
        "    ('office_name'               , ['office', 'name']),\n",
        "    ('street_name'          , ['street', 'name']),\n",
        "    ('street_digit'         , ['street', 'digit']),\n",
        "    ('street_code'          , ['street', 'code']),\n",
        "    ('army_name'            , ['army', 'code']),\n",
        "    ('army_name'            , ['army', 'digit']),\n",
        "    ('army_name'            , ['army', 'name'])\n",
        "]\n",
        "\n",
        "def sent_re_feature(sent):\n",
        "    l = len(sent)\n",
        "    sent_re_ft = ['NA'] * l\n",
        "    re_dict_word = [re_word(word[0]) for word in sent]\n",
        "    for type_name in re_type_name:\n",
        "        tl = len(type_name[1])\n",
        "        for i in range(l):\n",
        "            if (i + tl <= l):\n",
        "                if (set(['NA']) == set([sent_re_ft[i+j] for j in range(tl)])) and (set([True]) == set([re_dict_word[i+ll][type_name[1][ll]] for ll in range(tl)])):\n",
        "                    for k in range(tl):\n",
        "                        sent_re_ft[i+k] = type_name[0]\n",
        "    return sent_re_ft\n",
        "\n",
        "def sent_feature_train(sent):\n",
        "    sent_ft_train = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        if i < 1:\n",
        "            sent_ft_train.append((word_feature(sent, i, 'BOS', 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  len(labels)))\n",
        "        elif i < 2:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], 'BOS', sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))\n",
        "        else:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], sent[i-2][3], sent_re_ft),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))    \n",
        "    return sent_ft_train      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEpUrQIRwNQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_feature_test(sent, pre_state, pre_pre_state):\n",
        "    sent_ft_test = list()\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    for i in range(len(sent)):\n",
        "        sent_ft_test.append(word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft))    \n",
        "    return sent_ft_test      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLUitkgW_14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_decoder(model, sent):\n",
        "    sent_re_ft = sent_re_feature(sent)\n",
        "    alpha = [([None] * len(labels)) for i in range(len(sent))]\n",
        "    trace = np.full(shape=(len(sent), len(labels)), fill_value=-1)\n",
        "\n",
        "    # start probability\n",
        "    pdist = model[len(labels)].prob_classify(word_feature(sent, 0, 'BOS', 'BOS', sent_re_ft))    \n",
        "    alpha[0] = [pdist.prob(l) for l in labels]\n",
        "    \n",
        "    for i in range(1, len(sent)):\n",
        "        alpha[i] = [0] * len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            pre_state = labels[j];\n",
        "            pre_pre_state = 'BOS'\n",
        "            if i > 1:\n",
        "                pre_pre_state = labels[trace[i-1][j]];\n",
        "            feature = word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft)\n",
        "            pdist = model[j].prob_classify(feature)                \n",
        "            posterior = [pdist.prob(l) for l in labels]\n",
        "            for k in range(len(labels)):\n",
        "                if alpha[i][k] < (posterior[k] * alpha[i-1][j]):\n",
        "                    alpha[i][k] = posterior[k] * alpha[i-1][j]\n",
        "                    trace[i][k] = j\n",
        "    m = alpha[-1][0]\n",
        "    idx = 0\n",
        "    for i in range(1, len(alpha[-1])):\n",
        "        if (alpha[-1][i] > m):\n",
        "            m = alpha[-1][i]\n",
        "            idx = i;\n",
        "    predict = list()\n",
        "    for i in range(len(sent)-1, -1, -1):\n",
        "        predict.append(labels[idx])\n",
        "        idx = trace[i][idx]\n",
        "    # print(alpha)\n",
        "    return reversed(predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0c_283RGcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sent(model, sent):\n",
        "    y_test_sent = [sent[i][3] for i in range(len(sent))]   \n",
        "    y_pred_sent = viterbi_decoder(model, sent)\n",
        "    return y_test_sent, y_pred_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrrICItK-LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, sents):\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for sent in sents:\n",
        "        test, pred = predict_sent(model, sent)\n",
        "        y_test.extend(test)\n",
        "        y_pred.extend(pred)\n",
        "    return y_test, y_pred            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDuKHtwrqIFM",
        "colab_type": "code",
        "outputId": "448d76e7-4d6f-429e-cca9-8f1f597244aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_data, pos_tag, chunk_tag = prepare_data(data_path)\n",
        "train_sents, test_sents = train_test_split(all_data, test_size = 0.15, random_state=42)\n",
        "print(\"train_sents\", len(train_sents))\n",
        "print(\"test_sents\", len(test_sents))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents 14087\n",
            "test_sents 2486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1EC8jzHu-P",
        "colab_type": "code",
        "outputId": "3b376464-42b5-486b-8914-8d5bdc1d901e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "train_data = [[] for i in range(len(labels) + 1)]\n",
        "for sent in train_sents:\n",
        "    for feature, label, pre_label in sent_feature_train(sent):\n",
        "        train_data[pre_label].append((feature, labels[label]))     \n",
        "\n",
        "for i in range(len(labels) + 1):\n",
        "    print('train_data[' + str(i) +'] length', len(train_data[i]))\n",
        "    print(train_data[i][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data[0] length 6259\n",
            "({'w0': 'về', 's-1': 'B-PER', 's-2': 'O', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Phong', 'w-2': 'ông', 'w+1': 'Thái_Bình', 'w+2': 'thăm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA'}, 'O')\n",
            "train_data[1] length 2899\n",
            "({'w0': 'Bình', 's-1': 'I-PER', 's-2': 'B-PER', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trọng', 'w-2': 'Hồ', 'w+1': 'nói', 'w+2': ':', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA'}, 'I-PER')\n",
            "train_data[2] length 991\n",
            "({'w0': 'Kredtrakarn', 's-1': 'B-ORG', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trung_tâm', 'w-2': 'BOS', 'w+1': 'đang', 'w+2': 'tìm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA'}, 'I-ORG')\n",
            "train_data[3] length 1675\n",
            "({'w0': 'đang', 's-1': 'I-ORG', 's-2': 'B-ORG', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Kredtrakarn', 'w-2': 'Trung_tâm', 'w+1': 'tìm', 'w+2': 'địa_chỉ', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'NA', 'r+2': 'NA'}, 'O')\n",
            "train_data[4] length 5090\n",
            "({'w0': 'Mai', 's-1': 'B-LOC', 's-2': 'O', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'chợ', 'w-2': 'ở', 'w+1': 'Xuân', 'w+2': 'Thưởng', 'r0': 'place_name_name', 'r-1': 'place_name_name', 'r+1': 'place_name_name', 'r-2': 'NA', 'r+2': 'NA'}, 'I-LOC')\n",
            "train_data[5] length 2302\n",
            "({'w0': 'Xuân', 's-1': 'I-LOC', 's-2': 'B-LOC', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Mai', 'w-2': 'chợ', 'w+1': 'Thưởng', 'w+2': 'sẽ', 'r0': 'place_name_name', 'r-1': 'place_name_name', 'r+1': 'NA', 'r-2': 'place_name_name', 'r+2': 'NA'}, 'I-LOC')\n",
            "train_data[6] length 272497\n",
            "({'w0': 'một_số', 's-1': 'O', 's-2': 'BOS', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 2, 'is_name': False, 'w-1': 'Ngoài', 'w-2': 'BOS', 'w+1': 'nhỏ', 'w+2': 'gồm', 'r0': 'NA', 'r-1': 'NA', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA'}, 'O')\n",
            "train_data[7] length 14087\n",
            "({'w0': 'Ngoài', 's-1': 'BOS', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'BOS', 'w-2': 'BOS', 'w+1': 'một_số', 'w+2': 'nhỏ', 'r0': 'NA', 'r-1': 'BOS', 'r+1': 'NA', 'r-2': 'BOS', 'r+2': 'NA'}, 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DOocaPDqL4n",
        "colab_type": "code",
        "outputId": "1376e7f1-7be0-413e-9e6e-9cb241998da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time \n",
        "max_iter = 10\n",
        "model = [[] for i in range(len(labels) + 1)]\n",
        "for i in range(len(labels) + 1):\n",
        "    if i == 6:\n",
        "        continue\n",
        "    print(\"Training with pre_state\", i)\n",
        "    encoding = BinaryMaxentFeatureEncoding.train(train_data[i], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "    model[i]= MaxentClassifier.train(train_data[i], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "print(\"Training with pre_state\", 6)\n",
        "encoding_ = BinaryMaxentFeatureEncoding.train(train_data[6], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "model[6] = MaxentClassifier.train(train_data[6], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-multi-classifier-featureset2-binaryfeature-maxiter10.model\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with pre_state 0\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.714\n",
            "             2          -0.32961        0.825\n",
            "             3          -0.21667        0.988\n",
            "             4          -0.14881        0.988\n",
            "             5          -0.10783        0.988\n",
            "             6          -0.08209        0.988\n",
            "             7          -0.06522        0.988\n",
            "             8          -0.05371        0.988\n",
            "             9          -0.04557        0.989\n",
            "         Final          -0.03963        0.989\n",
            "Training with pre_state 1\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.614\n",
            "             2          -0.41075        0.962\n",
            "             3          -0.27942        0.963\n",
            "             4          -0.20446        0.963\n",
            "             5          -0.15926        0.963\n",
            "             6          -0.13034        0.963\n",
            "             7          -0.11078        0.964\n",
            "             8          -0.09689        0.966\n",
            "             9          -0.08660        0.967\n",
            "         Final          -0.07869        0.968\n",
            "Training with pre_state 2\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.222\n",
            "             2          -0.36009        0.770\n",
            "             3          -0.31672        0.775\n",
            "             4          -0.28196        0.815\n",
            "             5          -0.25417        0.884\n",
            "             6          -0.23190        0.941\n",
            "             7          -0.21384        0.956\n",
            "             8          -0.19898        0.960\n",
            "             9          -0.18657        0.962\n",
            "         Final          -0.17607        0.960\n",
            "Training with pre_state 3\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.436\n",
            "             2          -0.59627        0.897\n",
            "             3          -0.53100        0.910\n",
            "             4          -0.48088        0.916\n",
            "             5          -0.44149        0.920\n",
            "             6          -0.40977        0.922\n",
            "             7          -0.38365        0.923\n",
            "             8          -0.36172        0.923\n",
            "             9          -0.34303        0.924\n",
            "         Final          -0.32687        0.925\n",
            "Training with pre_state 4\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.60944        0.626\n",
            "             2          -0.40910        0.930\n",
            "             3          -0.29442        0.958\n",
            "             4          -0.22653        0.967\n",
            "             5          -0.18359        0.971\n",
            "             6          -0.15472        0.973\n",
            "             7          -0.13430        0.973\n",
            "             8          -0.11925        0.973\n",
            "             9          -0.10778        0.973\n",
            "         Final          -0.09877        0.972\n",
            "Training with pre_state 5\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.818\n",
            "             2          -0.27151        0.818\n",
            "             3          -0.21398        0.907\n",
            "             4          -0.17235        0.957\n",
            "             5          -0.14342        0.967\n",
            "             6          -0.12286        0.967\n",
            "             7          -0.10776        0.973\n",
            "             8          -0.09632        0.974\n",
            "             9          -0.08741        0.977\n",
            "         Final          -0.08030        0.977\n",
            "Training with pre_state 7\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.937\n",
            "             2          -0.12352        0.937\n",
            "             3          -0.12217        0.937\n",
            "             4          -0.12063        0.937\n",
            "             5          -0.11883        0.937\n",
            "             6          -0.11684        0.937\n",
            "             7          -0.11473        0.937\n",
            "             8          -0.11257        0.938\n",
            "             9          -0.11041        0.938\n",
            "         Final          -0.10829        0.939\n",
            "Training with pre_state 6\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94285        0.958\n",
            "             2          -0.07645        0.960\n",
            "             3          -0.07227        0.960\n",
            "             4          -0.06856        0.960\n",
            "             5          -0.06410        0.960\n",
            "             6          -0.05968        0.963\n",
            "             7          -0.05573        0.966\n",
            "             8          -0.05235        0.970\n",
            "             9          -0.04949        0.972\n",
            "         Final          -0.04708        0.973\n",
            "CPU times: user 27min 11s, sys: 3.68 s, total: 27min 15s\n",
            "Wall time: 27min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80hkGhIOBlua",
        "colab_type": "code",
        "outputId": "598f4fb2-4da8-409f-d64f-fb2a481496f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-multi-classifier-featureset2-binaryfeature-maxiter10.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['81.18%', '84.66%', '50.89%', '82.73%', '71.88%', '82.35%']\n",
            "recall:    ['70.58%', '89.16%', '9.9%', '20.97%', '13.94%', '14.43%']\n",
            "fscore:    ['75.51%', '86.85%', '16.57%', '33.46%', '23.35%', '24.56%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 73.69%\n",
            "total recall (weighted): 43.6%\n",
            "total fscore (weighted): 49.5%\n",
            "CPU times: user 55.8 s, sys: 18 ms, total: 55.8 s\n",
            "Wall time: 55.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PvZUnXSL41X",
        "colab_type": "code",
        "outputId": "e76b3b8e-694b-453b-c1d5-9f2397b5cf03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('model 0 ______________________________________________________')\n",
        "test_model[0].show_most_informative_features()\n",
        "print('model 1______________________________________________________')\n",
        "test_model[1].show_most_informative_features()\n",
        "print('model 2______________________________________________________')\n",
        "test_model[2].show_most_informative_features()\n",
        "print('model 3______________________________________________________')\n",
        "test_model[3].show_most_informative_features()\n",
        "print('model 4______________________________________________________')\n",
        "test_model[4].show_most_informative_features()\n",
        "print('model 5______________________________________________________')\n",
        "test_model[5].show_most_informative_features()\n",
        "print('model 6______________________________________________________')\n",
        "test_model[6].show_most_informative_features()\n",
        "print('model 7______________________________________________________')\n",
        "test_model[7].show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model 0 ______________________________________________________\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'B-LOC'\n",
            "    -inf label is 'I-LOC'\n",
            "  -2.402 is_title==True and label is 'O'\n",
            "  -2.190 is_name==True and label is 'O'\n",
            "  -1.865 is_lower==True and label is 'I-PER'\n",
            "  -1.159 has_hyphen==True and label is 'I-PER'\n",
            "   1.147 w0=='việt_dã' and label is 'I-PER'\n",
            "  -1.110 w+1=='Hiếu' and label is 'O'\n",
            "model 1______________________________________________________\n",
            "    -inf label is 'B-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "  -2.701 is_title==True and label is 'O'\n",
            "   2.593 w-2=='Lý' and label is 'B-LOC'\n",
            "  -2.101 is_name==True and label is 'O'\n",
            "   1.945 w+2==':' and label is 'B-LOC'\n",
            "  -1.272 w+1=='”' and label is 'O'\n",
            "  -1.234 w-2=='Văn' and label is 'I-PER'\n",
            "model 2______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "  -2.031 is_name==True and label is 'O'\n",
            "   2.008 w-2=='thuộc' and label is 'I-LOC'\n",
            "   1.800 has_hyphen==True and label is 'B-ORG'\n",
            "  -1.797 is_title==True and label is 'O'\n",
            "   1.761 w+1=='và' and label is 'I-LOC'\n",
            "   1.650 num_syllabus==3 and label is 'B-LOC'\n",
            "   1.511 r0=='adm_div' and label is 'B-LOC'\n",
            "   1.508 w-2=='trưởng' and label is 'B-ORG'\n",
            "  -1.465 r+1=='org_adm_div' and label is 'O'\n",
            "model 3______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "   3.096 w0=='Thái' and label is 'I-LOC'\n",
            "   2.132 w0=='Mỹ' and label is 'B-LOC'\n",
            "  -1.790 w0==',' and label is 'I-ORG'\n",
            "   1.720 w0=='Lê' and label is 'B-PER'\n",
            "   1.670 w-2=='về' and label is 'B-ORG'\n",
            "   1.644 w-1=='ma_tuý' and label is 'B-ORG'\n",
            "   1.637 w+2=='trước' and label is 'B-LOC'\n",
            "   1.631 w0=='Nguyễn' and label is 'B-PER'\n",
            "   1.514 w-2=='và' and label is 'B-ORG'\n",
            "model 4______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "   2.555 w-1=='Hàn_Quốc' and label is 'B-ORG'\n",
            "  -2.467 is_title==True and label is 'O'\n",
            "  -2.425 is_name==True and label is 'O'\n",
            "   2.328 w+1=='Thị' and label is 'B-PER'\n",
            "   2.249 w+2=='với' and label is 'B-ORG'\n",
            "   2.165 w+1=='...' and label is 'B-ORG'\n",
            "   1.964 w-2=='bạn' and label is 'B-PER'\n",
            "   1.964 w-1=='Lâm_Đồng' and label is 'B-PER'\n",
            "model 5______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "   2.371 w0=='Lê' and label is 'B-PER'\n",
            "   2.209 w+1=='Văn' and label is 'B-PER'\n",
            "  -1.829 is_title==True and label is 'O'\n",
            "  -1.636 is_name==True and label is 'O'\n",
            "   1.633 w-1=='Thống_Nhất' and label is 'B-LOC'\n",
            "   1.531 w-2=='thị_trấn' and label is 'B-PER'\n",
            "   1.509 r+1=='street_digit' and label is 'B-LOC'\n",
            "model 6______________________________________________________\n",
            "    -inf s-1=='BOS' and label is 'O'\n",
            "    -inf w-1=='BOS' and label is 'O'\n",
            "    -inf r-1=='BOS' and label is 'O'\n",
            "    -inf s-1=='BOS' and label is 'B-ORG'\n",
            "    -inf w-1=='BOS' and label is 'B-ORG'\n",
            "    -inf r-1=='BOS' and label is 'B-ORG'\n",
            "    -inf s-1=='BOS' and label is 'B-PER'\n",
            "    -inf w-1=='BOS' and label is 'B-PER'\n",
            "    -inf r-1=='BOS' and label is 'B-PER'\n",
            "    -inf s-1=='BOS' and label is 'B-LOC'\n",
            "model 7______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   2.336 w0=='Tuổi_Trẻ' and label is 'B-ORG'\n",
            "   2.079 w0=='Sông' and label is 'B-LOC'\n",
            "   2.020 w+2=='thế_giới' and label is 'B-ORG'\n",
            "   2.020 w0=='VN' and label is 'B-LOC'\n",
            "   1.985 w0=='Trung_tâm' and label is 'B-ORG'\n",
            "   1.950 w0=='Chợ' and label is 'B-LOC'\n",
            "   1.924 w+1=='Sài_Gòn' and label is 'B-ORG'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}