{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mem-multi-classifier-featureset1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gabUUCtVqD36",
        "colab_type": "code",
        "outputId": "74ee726f-d2c2-4fff-b427-66d3df9c467d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ceiuGTl2b0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pickle\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.classify.maxent import MaxentClassifier, BinaryMaxentFeatureEncoding\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF24ddXqaxc",
        "colab_type": "code",
        "outputId": "a75774e3-8b6d-48cc-8998-00c12675abaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Global variables\n",
        "rawdata_path = \"/content/gdrive/My Drive/ml/data/rawdata/\"\n",
        "data_path = \"/content/gdrive/My Drive/ml/data/data/\"\n",
        "model_path = \"/content/gdrive/My Drive/ml/model/\"\n",
        "labels = ['B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'O']\n",
        "labels_dict = {labels[i]: i for i in range(len(labels))}\n",
        "eval_labels = ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
        "print(labels_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOrPZ5D9qn3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "    ''' Create training data and testing data\n",
        "        Format of data: CoNLL\n",
        "\n",
        "        Args:\n",
        "        path: path of data folder\n",
        "        scale: test size\n",
        "        index_attri: Represents the number of attributes and the associated attribute type\n",
        "            index_attri == 1 : The number of attributes = 1 - only ner label. ex: [('Huế', 'B_LOC'), ('là', 'O'), ('thành_phố', 'O'), ('đẹp', 'O')]\n",
        "            index_attri == 2.1 : The number of attributes = 2(pos-tagging label, ner label). ex: [('Đó', 'P', 'O'), ('là', 'V',  'O'), ('con', 'Nc', 'O'), ('đường', 'N', , 'O')]\n",
        "            index_attri = 2.2 : The number of attributes = 2(chunking label, ner label). ex: [('Đó', 'B-NP', 'O'), ('là', 'B-VP', 'O'), ('con', 'B-NP', 'O'), ('đường', 'B-NP', 'O')]\n",
        "            index_attri = 3 : The number of attributes = 3(pos-tagging label,chunking, ner label). ex: [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')]\n",
        "            if index_attri not in {1,2.1,2,2,3} index_attri = 2.1\n",
        "        Return:\n",
        "        train_sents, test_sents\n",
        "        \n",
        "        Example of format data:\n",
        "        [[('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "        [('Đó', 'P', 'B-NP', 'O'), ('là', 'V', 'B-VP', 'O'), ('con', 'Nc', 'B-NP', 'O'), ('đường', 'N', 'B-NP', 'O')],\n",
        "    '''    \n",
        "    list_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    ''' Convert data format to CoNll '''\n",
        "    #training data\n",
        "    c = 0;\n",
        "    pos_tag = []\n",
        "    chunk_tag = []\n",
        "    ne_tag = []\n",
        "    for file in list_files:\n",
        "        with codecs.open(path + file,'r',encoding='utf8') as f:\n",
        "            sentence = []\n",
        "            remove = False\n",
        "            for line in f:\n",
        "                line = line.split()\n",
        "                if len(line) > 3:\n",
        "                    #label_set.append(line[3])\n",
        "                    if line[3] not in labels:\n",
        "                        remove = True\n",
        "                    else:\n",
        "                        pos_tag.append(line[1])\n",
        "                        chunk_tag.append(line[2])\n",
        "                    sentence.append((line[0],line[1],line[2],line[3]))\n",
        "                else:\n",
        "                    if len(sentence) > 0:\n",
        "                        if remove == False:                            \n",
        "                            all_data.append(sentence)\n",
        "                        else:\n",
        "                            remove = False\n",
        "                        sentence = []\n",
        "            f.close()\n",
        "\n",
        "    pos_tag = set(pos_tag)\n",
        "    chunk_tag = set(chunk_tag)\n",
        "    return  all_data, pos_tag, chunk_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ut2eUhP6TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_feature(word):\n",
        "    is_lower            = 'is_lower'\n",
        "    is_capital          = 'is_capital' \n",
        "    is_title            = 'is_title' \n",
        "    is_mix              = 'is_mix' \n",
        "    is_capital_period   = 'is_capital_period' \n",
        "    is_digit            = 'is_digit' \n",
        "    end_digit           = 'end_digit' \n",
        "    has_hyphen          = 'has_hyphen' \n",
        "    is_code             = 'is_code' \n",
        "    num_syllabus        = 'num_syllabus'\n",
        "    is_name             = 'is_name' \n",
        "\n",
        "    check_code = False\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            check_code = True\n",
        "            break;\n",
        "\n",
        "    ft = {\n",
        "        'bias'                : 1,\n",
        "        is_lower            : word.islower(),\n",
        "        is_capital          : word.isupper(),\n",
        "        is_title            : word.istitle(),\n",
        "        is_mix              : not(word.islower() and word.isupper()),\n",
        "        is_capital_period   : (('.' in word) and word[0].isupper()),\n",
        "        is_digit            : word.isdigit(),\n",
        "        end_digit           : word[-1].isdigit(),\n",
        "        has_hyphen          : ('-' in word),\n",
        "        is_code             : check_code,\n",
        "        num_syllabus        : (word.count('_') + 1),\n",
        "        is_name             : word[0].isupper()\n",
        "    }   \n",
        "    return ft\n",
        "\n",
        "def word_feature(sent, i, pre_state, pre_pre_state):\n",
        "    word = sent[i][0]\n",
        "    ft = dict()\n",
        "    ### basic feature \n",
        "    # current word\n",
        "    ft['w0'] = word\n",
        "    # previous entity tag\n",
        "    ft['s-1'] = pre_state\n",
        "    ft['s-2'] = pre_pre_state\n",
        "    ### basic shape feature\n",
        "    ft.update(shape_feature(word))\n",
        "    ### basic joint feature\n",
        "    if i > 0:\n",
        "        ft['w-1'] = sent[i-1][0]\n",
        "    else:\n",
        "        ft['w-1'] = 'BOS'\n",
        "    # ft['w0+w-1'] = ft['w0'] + ' ' + ft['w-1']\n",
        "    if i > 1:\n",
        "        ft['w-2'] = sent[i-2][0]\n",
        "    else:\n",
        "        ft['w-2'] = 'BOS'\n",
        "    if i < len(sent)-1:\n",
        "        ft['w+1'] = sent[i+1][0]#.replace('_', ' ')\n",
        "    else:\n",
        "        ft['w+1'] = 'EOS'\n",
        "    # ft['w0+w+1'] = ft['w0'] + ' ' + ft['w+1']\n",
        "    # ft['w0+s-1'] = ft['w0'] + ' ' + ft['s-1']\n",
        "    if i < len(sent)-2:\n",
        "        ft['w+2'] = sent[i+2][0]\n",
        "    else:\n",
        "        ft['w+2'] = 'EOS'\n",
        "    return ft\n",
        "\n",
        "def sent_feature_train(sent):\n",
        "    sent_ft_train = list()\n",
        "    for i in range(len(sent)):\n",
        "        if i < 1:\n",
        "            sent_ft_train.append((word_feature(sent, i, 'BOS', 'BOS'),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  len(labels)))\n",
        "        elif i < 2:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], 'BOS'),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))\n",
        "        else:\n",
        "            sent_ft_train.append((word_feature(sent, i, sent[i-1][3], sent[i-2][3]),\n",
        "                                  labels_dict[sent[i][3]],\n",
        "                                  labels_dict[sent[i-1][3]]))    \n",
        "    return sent_ft_train "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEpUrQIRwNQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_feature_test(sent, pre_state, pre_pre_state):\n",
        "    sent_ft_test = list()\n",
        "    for i in range(len(sent)):\n",
        "        sent_ft_test.append(word_feature(sent, i, pre_state, pre_pre_state, sent_re_ft))    \n",
        "    return sent_ft_test      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLUitkgW_14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_decoder(model, sent):\n",
        "    alpha = [([None] * len(labels)) for i in range(len(sent))]\n",
        "    trace = np.full(shape=(len(sent), len(labels)), fill_value=-1)\n",
        "\n",
        "    # start probability\n",
        "    pdist = model[len(labels)].prob_classify(word_feature(sent, 0, 'BOS', 'BOS'))    \n",
        "    alpha[0] = [pdist.prob(l) for l in labels]\n",
        "    \n",
        "    for i in range(1, len(sent)):\n",
        "        alpha[i] = [0] * len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            pre_state = labels[j];\n",
        "            pre_pre_state = 'BOS'\n",
        "            if i > 1:\n",
        "                pre_pre_state = labels[trace[i-1][j]];\n",
        "            feature = word_feature(sent, i, pre_state, pre_pre_state)\n",
        "            pdist = model[j].prob_classify(feature)                \n",
        "            posterior = [pdist.prob(l) for l in labels]\n",
        "            for k in range(len(labels)):\n",
        "                if alpha[i][k] < (posterior[k] * alpha[i-1][j]):\n",
        "                    alpha[i][k] = posterior[k] * alpha[i-1][j]\n",
        "                    trace[i][k] = j\n",
        "    m = alpha[-1][0]\n",
        "    idx = 0\n",
        "    for i in range(1, len(alpha[-1])):\n",
        "        if (alpha[-1][i] > m):\n",
        "            m = alpha[-1][i]\n",
        "            idx = i;\n",
        "    predict = list()\n",
        "    for i in range(len(sent)-1, -1, -1):\n",
        "        predict.append(labels[idx])\n",
        "        idx = trace[i][idx]\n",
        "    # print(alpha)\n",
        "    return reversed(predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0c_283RGcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sent(model, sent):\n",
        "    y_test_sent = [sent[i][3] for i in range(len(sent))]   \n",
        "    y_pred_sent = viterbi_decoder(model, sent)\n",
        "    return y_test_sent, y_pred_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrrICItK-LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, sents):\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for sent in sents:\n",
        "        test, pred = predict_sent(model, sent)\n",
        "        y_test.extend(test)\n",
        "        y_pred.extend(pred)\n",
        "    return y_test, y_pred            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDuKHtwrqIFM",
        "colab_type": "code",
        "outputId": "9036c136-0264-4309-9eeb-c1a5f86ccda7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_data, pos_tag, chunk_tag = prepare_data(data_path)\n",
        "train_sents, test_sents = train_test_split(all_data, test_size = 0.15, random_state=42)\n",
        "print(\"train_sents\", len(train_sents))\n",
        "print(\"test_sents\", len(test_sents))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents 14087\n",
            "test_sents 2486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1EC8jzHu-P",
        "colab_type": "code",
        "outputId": "513d7487-8a61-46af-9c8b-08d6548f3068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "train_data = [[] for i in range(len(labels) + 1)]\n",
        "for sent in train_sents:\n",
        "    for feature, label, pre_label in sent_feature_train(sent):\n",
        "        train_data[pre_label].append((feature, labels[label]))     \n",
        "\n",
        "for i in range(len(labels) + 1):\n",
        "    print('train_data[' + str(i) +'] length', len(train_data[i]))\n",
        "    print(train_data[i][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data[0] length 6259\n",
            "({'w0': 'về', 's-1': 'B-PER', 's-2': 'O', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Phong', 'w-2': 'ông', 'w+1': 'Thái_Bình', 'w+2': 'thăm'}, 'O')\n",
            "train_data[1] length 2899\n",
            "({'w0': 'Bình', 's-1': 'I-PER', 's-2': 'B-PER', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trọng', 'w-2': 'Hồ', 'w+1': 'nói', 'w+2': ':'}, 'I-PER')\n",
            "train_data[2] length 991\n",
            "({'w0': 'Kredtrakarn', 's-1': 'B-ORG', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Trung_tâm', 'w-2': 'BOS', 'w+1': 'đang', 'w+2': 'tìm'}, 'I-ORG')\n",
            "train_data[3] length 1675\n",
            "({'w0': 'đang', 's-1': 'I-ORG', 's-2': 'B-ORG', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': False, 'w-1': 'Kredtrakarn', 'w-2': 'Trung_tâm', 'w+1': 'tìm', 'w+2': 'địa_chỉ'}, 'O')\n",
            "train_data[4] length 5090\n",
            "({'w0': 'Mai', 's-1': 'B-LOC', 's-2': 'O', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'chợ', 'w-2': 'ở', 'w+1': 'Xuân', 'w+2': 'Thưởng'}, 'I-LOC')\n",
            "train_data[5] length 2302\n",
            "({'w0': 'Xuân', 's-1': 'I-LOC', 's-2': 'B-LOC', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'Mai', 'w-2': 'chợ', 'w+1': 'Thưởng', 'w+2': 'sẽ'}, 'I-LOC')\n",
            "train_data[6] length 272497\n",
            "({'w0': 'một_số', 's-1': 'O', 's-2': 'BOS', 'bias': 1, 'is_lower': True, 'is_capital': False, 'is_title': False, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 2, 'is_name': False, 'w-1': 'Ngoài', 'w-2': 'BOS', 'w+1': 'nhỏ', 'w+2': 'gồm'}, 'O')\n",
            "train_data[7] length 14087\n",
            "({'w0': 'Ngoài', 's-1': 'BOS', 's-2': 'BOS', 'bias': 1, 'is_lower': False, 'is_capital': False, 'is_title': True, 'is_mix': True, 'is_capital_period': False, 'is_digit': False, 'end_digit': False, 'has_hyphen': False, 'is_code': False, 'num_syllabus': 1, 'is_name': True, 'w-1': 'BOS', 'w-2': 'BOS', 'w+1': 'một_số', 'w+2': 'nhỏ'}, 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DOocaPDqL4n",
        "colab_type": "code",
        "outputId": "27e4de30-80e0-4496-8d9c-c5ae4fb92241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time \n",
        "max_iter = 10\n",
        "model = [[] for i in range(len(labels) + 1)]\n",
        "for i in range(len(labels) + 1):\n",
        "    if i == 6:\n",
        "        continue\n",
        "    print(\"Training with pre_state\", i)\n",
        "    encoding = BinaryMaxentFeatureEncoding.train(train_data[i], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "    model[i]= MaxentClassifier.train(train_data[i], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "print(\"Training with pre_state\", 6)\n",
        "encoding_ = BinaryMaxentFeatureEncoding.train(train_data[6], count_cutoff=3, labels = labels, alwayson_features=True)\n",
        "model[6] = MaxentClassifier.train(train_data[6], algorithm = 'iis', trace=3, encoding=encoding, max_iter=max_iter)\n",
        "# save model\n",
        "pickle.dump(model, open(model_path + \"mem-multi-classifier-featureset1-binaryfeature-maxiter10.model\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with pre_state 0\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.714\n",
            "             2          -0.28736        0.968\n",
            "             3          -0.17054        0.988\n",
            "             4          -0.11037        0.989\n",
            "             5          -0.07775        0.989\n",
            "             6          -0.05873        0.989\n",
            "             7          -0.04691        0.989\n",
            "             8          -0.03912        0.989\n",
            "             9          -0.03374        0.989\n",
            "         Final          -0.02987        0.991\n",
            "Training with pre_state 1\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.614\n",
            "             2          -0.36150        0.963\n",
            "             3          -0.22902        0.963\n",
            "             4          -0.16295        0.963\n",
            "             5          -0.12638        0.963\n",
            "             6          -0.10412        0.967\n",
            "             7          -0.08944        0.967\n",
            "             8          -0.07909        0.968\n",
            "             9          -0.07137        0.970\n",
            "         Final          -0.06535        0.971\n",
            "Training with pre_state 2\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.222\n",
            "             2          -0.34818        0.770\n",
            "             3          -0.30311        0.784\n",
            "             4          -0.26886        0.841\n",
            "             5          -0.24262        0.913\n",
            "             6          -0.22226        0.951\n",
            "             7          -0.20608        0.961\n",
            "             8          -0.19292        0.963\n",
            "             9          -0.18198        0.967\n",
            "         Final          -0.17274        0.965\n",
            "Training with pre_state 3\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.79176        0.436\n",
            "             2          -0.58041        0.911\n",
            "             3          -0.51197        0.918\n",
            "             4          -0.46051        0.921\n",
            "             5          -0.42072        0.919\n",
            "             6          -0.38910        0.920\n",
            "             7          -0.36338        0.922\n",
            "             8          -0.34201        0.924\n",
            "             9          -0.32396        0.925\n",
            "         Final          -0.30849        0.927\n",
            "Training with pre_state 4\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.60944        0.626\n",
            "             2          -0.39911        0.959\n",
            "             3          -0.27873        0.971\n",
            "             4          -0.20934        0.973\n",
            "             5          -0.16682        0.973\n",
            "             6          -0.13914        0.973\n",
            "             7          -0.12014        0.972\n",
            "             8          -0.10648        0.972\n",
            "             9          -0.09627        0.972\n",
            "         Final          -0.08838        0.972\n",
            "Training with pre_state 5\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.818\n",
            "             2          -0.26707        0.823\n",
            "             3          -0.20428        0.945\n",
            "             4          -0.16024        0.967\n",
            "             5          -0.13064        0.974\n",
            "             6          -0.11035        0.977\n",
            "             7          -0.09598        0.977\n",
            "             8          -0.08547        0.978\n",
            "             9          -0.07754        0.978\n",
            "         Final          -0.07139        0.980\n",
            "Training with pre_state 7\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.38629        0.937\n",
            "             2          -0.12338        0.937\n",
            "             3          -0.12177        0.937\n",
            "             4          -0.11990        0.937\n",
            "             5          -0.11773        0.937\n",
            "             6          -0.11539        0.937\n",
            "             7          -0.11299        0.937\n",
            "             8          -0.11057        0.939\n",
            "             9          -0.10820        0.939\n",
            "         Final          -0.10589        0.939\n",
            "Training with pre_state 6\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.94285        0.958\n",
            "             2          -0.07573        0.960\n",
            "             3          -0.07098        0.960\n",
            "             4          -0.06638        0.960\n",
            "             5          -0.06140        0.962\n",
            "             6          -0.05698        0.966\n",
            "             7          -0.05334        0.970\n",
            "             8          -0.05039        0.972\n",
            "             9          -0.04798        0.974\n",
            "         Final          -0.04601        0.974\n",
            "CPU times: user 22min 30s, sys: 3.57 s, total: 22min 33s\n",
            "Wall time: 22min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80hkGhIOBlua",
        "colab_type": "code",
        "outputId": "368d790a-4506-463a-afa8-609da089d5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "%%time\n",
        "# test model\n",
        "test_model = pickle.load(open(model_path + \"mem-multi-classifier-featureset1-binaryfeature-maxiter10.model\", \"rb\"))\n",
        "y_test, y_pred = predict(test_model, test_sents)\n",
        "precision, recall, fscore, support = score(y_test, y_pred, labels=eval_labels)\n",
        "print('labels:    {}'.format(eval_labels))\n",
        "print('precision: {}'.format([str(round(p*100,2)) + '%' for p in precision]))\n",
        "print('recall:    {}'.format([str(round(r*100,2)) + '%' for r in recall]))\n",
        "print('fscore:    {}'.format([str(round(f*100,2)) + '%' for f in fscore]))\n",
        "print('support:   {}'.format(support))\n",
        "total_precision = metrics.precision_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_recall = metrics.recall_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "total_fscore = metrics.f1_score(y_test, y_pred, average='weighted', labels=eval_labels)\n",
        "print('total precision (weighted): {}'.format(str(round(total_precision*100,2)) + '%'))\n",
        "print('total recall (weighted): {}'.format(str(round(total_recall*100,2)) + '%'))\n",
        "print('total fscore (weighted): {}'.format(str(round(total_fscore*100,2)) + '%'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:    ['B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n",
            "precision: ['72.96%', '81.49%', '24.21%', '27.78%', '100.0%', '100.0%']\n",
            "recall:    ['80.42%', '89.54%', '2.65%', '1.15%', '1.21%', '1.37%']\n",
            "fscore:    ['76.51%', '85.33%', '4.77%', '2.21%', '2.4%', '2.71%']\n",
            "support:   [1057  526  869  434  165  291]\n",
            "total precision (weighted): 59.45%\n",
            "total recall (weighted): 40.54%\n",
            "total fscore (weighted): 39.51%\n",
            "CPU times: user 42.9 s, sys: 20 ms, total: 42.9 s\n",
            "Wall time: 43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk3N7m9WJtGQ",
        "colab_type": "code",
        "outputId": "b2f59822-b01d-4d48-b637-dbeacced0469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('model 0 ______________________________________________________')\n",
        "test_model[0].show_most_informative_features()\n",
        "print('model 1______________________________________________________')\n",
        "test_model[1].show_most_informative_features()\n",
        "print('model 2______________________________________________________')\n",
        "test_model[2].show_most_informative_features()\n",
        "print('model 3______________________________________________________')\n",
        "test_model[3].show_most_informative_features()\n",
        "print('model 4______________________________________________________')\n",
        "test_model[4].show_most_informative_features()\n",
        "print('model 5______________________________________________________')\n",
        "test_model[5].show_most_informative_features()\n",
        "print('model 6______________________________________________________')\n",
        "test_model[6].show_most_informative_features()\n",
        "print('model 7______________________________________________________')\n",
        "test_model[7].show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'B-LOC'\n",
            "    -inf label is 'I-LOC'\n",
            "  -2.821 is_title==True and label is 'O'\n",
            "  -2.555 is_name==True and label is 'O'\n",
            "  -2.170 is_lower==True and label is 'I-PER'\n",
            "   1.530 w0=='việt_dã' and label is 'I-PER'\n",
            "  -1.334 has_hyphen==True and label is 'I-PER'\n",
            "  -1.228 w-1=='Chương' and label is 'I-PER'\n",
            "______________________________________________________\n",
            "    -inf label is 'B-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   3.252 w-2=='Lý' and label is 'B-LOC'\n",
            "  -3.176 is_title==True and label is 'O'\n",
            "   2.429 w+2==':' and label is 'B-LOC'\n",
            "  -2.419 is_name==True and label is 'O'\n",
            "  -1.566 w+1=='”' and label is 'O'\n",
            "  -1.440 w+2=='tuổi' and label is 'I-PER'\n",
            "______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "  -2.400 is_name==True and label is 'O'\n",
            "   2.318 has_hyphen==True and label is 'B-ORG'\n",
            "   2.307 w-2=='thuộc' and label is 'I-LOC'\n",
            "  -2.077 is_title==True and label is 'O'\n",
            "   2.002 w+1=='và' and label is 'I-LOC'\n",
            "   1.976 num_syllabus==3 and label is 'B-LOC'\n",
            "   1.656 w-1=='Phòng' and label is 'B-ORG'\n",
            "   1.653 w-2=='trưởng' and label is 'B-ORG'\n",
            "  -1.614 w-1=='Tuổi_Trẻ' and label is 'I-ORG'\n",
            "______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "   3.673 w0=='Thái' and label is 'I-LOC'\n",
            "   2.450 w0=='Mỹ' and label is 'B-LOC'\n",
            "   2.276 w+2=='trước' and label is 'B-LOC'\n",
            "  -2.179 w0==',' and label is 'I-ORG'\n",
            "   2.082 w0=='tỉnh' and label is 'B-LOC'\n",
            "  -2.053 w+1=='EOS' and label is 'I-ORG'\n",
            "   2.000 w0=='Lê' and label is 'B-PER'\n",
            "   1.901 w-1=='ma_tuý' and label is 'B-ORG'\n",
            "   1.883 w0=='Nguyễn' and label is 'B-PER'\n",
            "______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "  -2.937 is_title==True and label is 'O'\n",
            "  -2.900 is_name==True and label is 'O'\n",
            "   2.837 w-1=='Hàn_Quốc' and label is 'B-ORG'\n",
            "   2.689 w+1=='Thị' and label is 'B-PER'\n",
            "   2.505 w+2=='với' and label is 'B-ORG'\n",
            "   2.463 w+1=='...' and label is 'B-ORG'\n",
            "   2.281 w0=='Châu_Thành' and label is 'B-LOC'\n",
            "   2.255 w-2=='bạn' and label is 'B-PER'\n",
            "______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'B-ORG'\n",
            "    -inf label is 'I-ORG'\n",
            "   2.873 w0=='Lê' and label is 'B-PER'\n",
            "   2.602 w+1=='Văn' and label is 'B-PER'\n",
            "  -2.221 is_title==True and label is 'O'\n",
            "   2.203 w+1=='Nguyễn' and label is 'B-LOC'\n",
            "   1.995 w-2=='thị_trấn' and label is 'B-PER'\n",
            "  -1.982 is_name==True and label is 'O'\n",
            "   1.794 w-1=='Thống_Nhất' and label is 'B-LOC'\n",
            "______________________________________________________\n",
            "    -inf s-1=='BOS' and label is 'O'\n",
            "    -inf w-1=='BOS' and label is 'O'\n",
            "    -inf s-1=='BOS' and label is 'B-ORG'\n",
            "    -inf w-1=='BOS' and label is 'B-ORG'\n",
            "    -inf s-1=='BOS' and label is 'B-PER'\n",
            "    -inf w-1=='BOS' and label is 'B-PER'\n",
            "    -inf s-1=='BOS' and label is 'B-LOC'\n",
            "    -inf w-1=='BOS' and label is 'B-LOC'\n",
            "    -inf w0=='Hiện' and label is 'O'\n",
            "    -inf w0=='Mọi' and label is 'O'\n",
            "______________________________________________________\n",
            "    -inf label is 'I-PER'\n",
            "    -inf label is 'I-ORG'\n",
            "    -inf label is 'I-LOC'\n",
            "   2.758 w0=='Hội' and label is 'B-ORG'\n",
            "   2.728 w0=='Tuổi_Trẻ' and label is 'B-ORG'\n",
            "   2.596 w0=='Tờ' and label is 'B-ORG'\n",
            "   2.443 w0=='Trung_tâm' and label is 'B-ORG'\n",
            "   2.440 w0=='Sông' and label is 'B-LOC'\n",
            "   2.387 w0=='VN' and label is 'B-LOC'\n",
            "   2.376 w+2=='thế_giới' and label is 'B-ORG'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}